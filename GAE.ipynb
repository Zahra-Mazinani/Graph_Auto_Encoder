{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahra-Mazinani/Graph_Auto_Encoder/blob/main/GAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "E1CcRpGCX3De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1fQJjL4LYWf",
        "outputId": "fca6184a-c03c-4dee-bcb2-bb1f105778ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gae'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 83 (delta 20), reused 19 (delta 19), pack-reused 52\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tkipf/gae.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2DKBYKfWLjdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f607ff2-81c0-4825-b173-74d03833807c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating gae.egg-info\n",
            "writing gae.egg-info/PKG-INFO\n",
            "writing dependency_links to gae.egg-info/dependency_links.txt\n",
            "writing requirements to gae.egg-info/requires.txt\n",
            "writing top-level names to gae.egg-info/top_level.txt\n",
            "writing manifest file 'gae.egg-info/SOURCES.txt'\n",
            "writing manifest file 'gae.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/gae-0.0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing gae-0.0.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Copying gae-0.0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "gae 0.0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Processing dependencies for gae==0.0.1\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.3\n",
            "Best match: networkx 2.6.3\n",
            "Adding networkx 2.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow==2.9.2\n",
            "Best match: tensorflow 2.9.2\n",
            "Adding tensorflow 2.9.2 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing import_pb_to_tensorboard script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for libclang==14.0.6\n",
            "Best match: libclang 14.0.6\n",
            "Adding libclang 14.0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for flatbuffers==1.12\n",
            "Best match: flatbuffers 1.12\n",
            "Adding flatbuffers 1.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opt-einsum==3.3.0\n",
            "Best match: opt-einsum 3.3.0\n",
            "Adding opt-einsum 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for keras==2.9.0\n",
            "Best match: keras 2.9.0\n",
            "Adding keras 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.49.1\n",
            "Best match: grpcio 1.49.1\n",
            "Adding grpcio 1.49.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.9.1\n",
            "Best match: tensorboard 2.9.1\n",
            "Adding tensorboard 2.9.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gast==0.4.0\n",
            "Best match: gast 0.4.0\n",
            "Adding gast 0.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-io-gcs-filesystem==0.27.0\n",
            "Best match: tensorflow-io-gcs-filesystem 0.27.0\n",
            "Adding tensorflow-io-gcs-filesystem 0.27.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wrapt==1.14.1\n",
            "Best match: wrapt 1.14.1\n",
            "Adding wrapt 1.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for h5py==3.1.0\n",
            "Best match: h5py 3.1.0\n",
            "Adding h5py 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-estimator==2.9.0\n",
            "Best match: tensorflow-estimator 2.9.0\n",
            "Adding tensorflow-estimator 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==2.0.1\n",
            "Best match: termcolor 2.0.1\n",
            "Adding termcolor 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cached-property==1.5.2\n",
            "Best match: cached-property 1.5.2\n",
            "Adding cached-property 1.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.9.24\n",
            "Best match: certifi 2022.9.24\n",
            "Adding certifi 2022.9.24 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.13.0\n",
            "Best match: importlib-metadata 4.13.0\n",
            "Adding importlib-metadata 4.13.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.9.0\n",
            "Best match: zipp 3.9.0\n",
            "Adding zipp 3.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.1\n",
            "Best match: oauthlib 3.2.1\n",
            "Adding oauthlib 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for gae==0.0.1\n"
          ]
        }
      ],
      "source": [
        "# In cell ro bardar. Lazem nadari\n",
        "\n",
        "!python /content/gae/setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "egtdHtZEYBD7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializations"
      ],
      "metadata": {
        "id": "3kPmH5zMYj6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "k_tGZM3fM11T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
        "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010)\n",
        "    initialization.\n",
        "    \"\"\"\n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n",
        "                                maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input data"
      ],
      "metadata": {
        "id": "1G_VlvyFZFWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "kh0JUMJ3fzWd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index"
      ],
      "metadata": {
        "id": "woM31ouTf2a1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"data/ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "metadata": {
        "id": "DT6QoeI5ZD0j"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "GFs3RJdIZ995"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8JFBub93cjhG"
      },
      "outputs": [],
      "source": [
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CZeEkbLCpYqt"
      },
      "outputs": [],
      "source": [
        "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
        "    # construct feed dictionary\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
        "    feed_dict.update({placeholders['adj_orig']: adj})\n",
        "    return feed_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)"
      ],
      "metadata": {
        "id": "XD6OoK30c-Br"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IxSUBYYdcaQg"
      },
      "outputs": [],
      "source": [
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Layers"
      ],
      "metadata": {
        "id": "YgNYjfErZiEV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0p4M7MNJt5"
      },
      "source": [
        "https://www.programcreek.com/python/\n",
        "\n",
        "https://book.pythontips.com/en/latest/args_and_kwargs.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# global unique layer ID dictionary for layer name assignment\n",
        "_LAYER_UIDS = {}"
      ],
      "metadata": {
        "id": "qLV8gOgGf8zY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layer_uid(layer_name=''):\n",
        "    \"\"\"Helper function, assigns unique layer IDs\n",
        "    \"\"\"\n",
        "    if layer_name not in _LAYER_UIDS:\n",
        "        _LAYER_UIDS[layer_name] = 1\n",
        "        return 1\n",
        "    else:\n",
        "        _LAYER_UIDS[layer_name] += 1\n",
        "        return _LAYER_UIDS[layer_name]"
      ],
      "metadata": {
        "id": "f8FMscFIf-uF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
        "    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n",
        "    \"\"\"\n",
        "    noise_shape = [num_nonzero_elems]\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1./keep_prob)"
      ],
      "metadata": {
        "id": "6LVe-UZigCrJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(object):\n",
        "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
        "\n",
        "    # Properties\n",
        "        name: String, defines the variable scope of the layer.\n",
        "\n",
        "    # Methods\n",
        "        _call(inputs): Defines computation graph of layer\n",
        "            (i.e. takes input, returns output)\n",
        "        __call__(inputs): Wrapper for _call()\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            layer = self.__class__.__name__.lower()\n",
        "            name = layer + '_' + str(get_layer_uid(layer))\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "        self.issparse = False\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            outputs = self._call(inputs)\n",
        "            return outputs"
      ],
      "metadata": {
        "id": "Q_QqoKTygNms"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(Layer):\n",
        "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolution, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = tf.nn.dropout(x, 1-self.dropout)\n",
        "        x = tf.matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "-hqbqd1ygQSX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolutionSparse(Layer):\n",
        "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolutionSparse, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = True\n",
        "        self.features_nonzero = features_nonzero\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
        "        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "JmZoQ9-OgVG3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wtHW27IUMvic"
      },
      "outputs": [],
      "source": [
        "class InnerProductDecoder(Layer):\n",
        "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
        "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
        "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
        "        x = tf.transpose(inputs)\n",
        "        x = tf.matmul(inputs, x)\n",
        "        x = tf.reshape(x, [-1])\n",
        "        outputs = self.act(x)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "LxOUv5YHYJ19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "DKID7cetnyDO"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            name = self.__class__.__name__.lower()\n",
        "        self.name = name\n",
        "\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "\n",
        "        self.vars = {}\n",
        "\n",
        "    def _build(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\" Wrapper for _build() \"\"\"\n",
        "        with tf.variable_scope(self.name):\n",
        "            self._build()\n",
        "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "        self.vars = {var.name: var for var in variables}\n",
        "\n",
        "    def fit(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "NUpRwgUan07z"
      },
      "outputs": [],
      "source": [
        "class GCNModelAE(Model):\n",
        "    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n",
        "        super(GCNModelAE, self).__init__(**kwargs)\n",
        "\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = num_features\n",
        "        self.features_nonzero = features_nonzero\n",
        "        self.adj = placeholders['adj']\n",
        "        self.dropout = placeholders['dropout']\n",
        "        self.build()\n",
        "\n",
        "    def _build(self):\n",
        "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
        "                                              output_dim=hidden1,\n",
        "                                              adj=self.adj,\n",
        "                                              features_nonzero=self.features_nonzero,\n",
        "                                              act=tf.nn.relu,\n",
        "                                              dropout=self.dropout,\n",
        "                                              logging=self.logging)(self.inputs)\n",
        "\n",
        "        self.embeddings = GraphConvolution(input_dim=hidden1,\n",
        "                                           output_dim=hidden2,\n",
        "                                           adj=self.adj,\n",
        "                                           act=lambda x: x,\n",
        "                                           dropout=self.dropout,\n",
        "                                           logging=self.logging)(self.hidden1)\n",
        "\n",
        "        self.z_mean = self.embeddings\n",
        "\n",
        "        self.reconstructions = InnerProductDecoder(input_dim=hidden2,\n",
        "                                      act=lambda x: x,\n",
        "                                      logging=self.logging)(self.embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimizer"
      ],
      "metadata": {
        "id": "fBL84Q2LZsiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# flags = tf.app.flags\n",
        "# FLAGS = flags.FLAGS"
      ],
      "metadata": {
        "id": "BwCYnv5Dgf4x"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizerAE(object):\n",
        "    def __init__(self, preds, labels, pos_weight, norm):\n",
        "        preds_sub = preds\n",
        "        labels_sub = labels\n",
        "\n",
        "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # Adam Optimizer\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.cost)\n",
        "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "                                           tf.cast(labels_sub, tf.int32))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"
      ],
      "metadata": {
        "id": "tYcpYZWBgmxf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ShIRo1amL_t3"
      },
      "outputs": [],
      "source": [
        "# class OptimizerVAE(object):\n",
        "#     def __init__(self, preds, labels, model, num_nodes, pos_weight, norm):\n",
        "#         preds_sub = preds\n",
        "#         labels_sub = labels\n",
        "\n",
        "#         self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "#         self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
        "\n",
        "#         # Latent loss\n",
        "#         self.log_lik = self.cost\n",
        "#         self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n",
        "#                                                                    tf.square(tf.exp(model.z_log_std)), 1))\n",
        "#         self.cost -= self.kl\n",
        "\n",
        "#         self.opt_op = self.optimizer.minimize(self.cost)\n",
        "#         self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "#         self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "#                                            tf.cast(labels_sub, tf.int32))\n",
        "#         self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "aXlIP2yNZ7hY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "KO7kRq_9Lm-_"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Train on CPU (hide GPU) due to memory constraints\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qALETgJ4a12s",
        "outputId": "85afed81-36e1-4478-b662-e809f7e3848c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gae/gae\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gae/gae"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings\n",
        "hyper parameters"
      ],
      "metadata": {
        "id": "FexCj7amebmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mvMX8Zoabw3H"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "\n",
        "learning_rate= 0.01\n",
        "epochs= 200\n",
        "hidden1= 32\n",
        "hidden2= 16\n",
        "weight_decay= 0\n",
        "dropout= 0\n",
        "\n",
        "\n",
        "# model_str = model\n",
        "dataset_str = 'cora'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data \n"
      ],
      "metadata": {
        "id": "c-vkeh4iefx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6fKASODfbPaI"
      },
      "outputs": [],
      "source": [
        "# Load data \n",
        "adj, features = load_data(dataset_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a84Cbz1vhJwk"
      },
      "source": [
        "Our own data instead of above run\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yAGhnjXurh4S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKS81wsIjnZU",
        "outputId": "1683c3ec-7800-4e71-9c02-d5c0df668b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "-WgOpNUsjnim"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Content_Top1-BERT.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')\n",
        "# data = list(objecta.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "3F5lER9VqH1O"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta)\n",
        "node_names = tmp.columns\n",
        "nodeslist = tmp.columns.values\n",
        "# np.sum(nodeslist == 26285)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "XHVC01-TjnrQ"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta).to_numpy()\n",
        "feats = tmp.transpose()\n",
        "# print(feats.shape)\n",
        "features = sp.lil_matrix(feats)\n",
        "tmp=pd.DataFrame.from_dict(objecta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "En452TQ3mT_H"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Indexes_Top1-byTRM-Dic.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')\n",
        "# objecta.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "evZeURKGkY71"
      },
      "outputs": [],
      "source": [
        "edjs=[]\n",
        "for idx, targets in objecta.items():\n",
        "  if idx in nodeslist:\n",
        "    target_str = targets.split(',')\n",
        "    for j in target_str:\n",
        "      if int(j) in nodeslist:\n",
        "        edjs.append((idx, int(j)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "5mSGObhxkZHC"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph()\n",
        "G.add_edges_from(edjs)\n",
        "# A = nx.adjacency_matrix(G, nodelist=nodeslist)\n",
        "degrees = [node for (node, val) in G.degree() if val>1]\n",
        "A = nx.adjacency_matrix(G, nodelist=degrees)\n",
        "# A.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "lAu4CJXNs2DK"
      },
      "outputs": [],
      "source": [
        "feats = tmp.loc[:, degrees].transpose()\n",
        "# feats.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "q_7fpGkSu64B"
      },
      "outputs": [],
      "source": [
        "features = sp.lil_matrix(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "l0SjN0nRhMre"
      },
      "outputs": [],
      "source": [
        "adj=A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store original adjacency matrix (without diagonal entries) for later\n"
      ],
      "metadata": {
        "id": "Yo3kcZHDe0A5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "vOLk0K_PbqUy"
      },
      "outputs": [],
      "source": [
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "\n",
        "# if FLAGS.features == 0:\n",
        "#     features = sp.identity(features.shape[0])  # featureless"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some preprocessing"
      ],
      "metadata": {
        "id": "Abq6PpoFe46m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "QugchzLycEZm"
      },
      "outputs": [],
      "source": [
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b_l7fZodN5G",
        "outputId": "93f3199c-3864-4434-fc14-cd09961d37a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define placeholders"
      ],
      "metadata": {
        "id": "FyUHfYHue8OO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "d-hrR_zycoeh"
      },
      "outputs": [],
      "source": [
        "# Define placeholders\n",
        "placeholders = {\n",
        "    'features': tf.sparse_placeholder(tf.float32),\n",
        "    'adj': tf.sparse_placeholder(tf.float32),\n",
        "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
        "    'dropout': tf.placeholder_with_default(0., shape=())\n",
        "}\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = sparse_to_tuple(features.tocoo())\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "JRg6Fbe-e_50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAjx-RaEcytI",
        "outputId": "a6bf2915-4fdf-4708-98c5-a00dace52676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
        "\n",
        "\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "aFJYyhCDfDn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g-EgrcSdVDR",
        "outputId": "0bb1d137-7a23-4142-e169-da9e2b469553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "targets is deprecated, use labels instead\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "opt = OptimizerAE(preds=model.reconstructions,\n",
        "                          labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
        "                                                                      validate_indices=False), [-1]),\n",
        "                          pos_weight=pos_weight,\n",
        "                          norm=norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize session"
      ],
      "metadata": {
        "id": "UytevRDJfF0U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "TJ0NPP0moyQp"
      },
      "outputs": [],
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "cost_val = []\n",
        "acc_val = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "gFa4oL16pEjc"
      },
      "outputs": [],
      "source": [
        "def get_roc_score(edges_pos, edges_neg, emb=None):\n",
        "    if emb is None:\n",
        "        feed_dict.update({placeholders['dropout']: 0})\n",
        "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "eO7IVCBlpHK4"
      },
      "outputs": [],
      "source": [
        "cost_val = []\n",
        "acc_val = []\n",
        "val_roc_score = []\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "y3zzE68afLr6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTcXDRicpIhK",
        "outputId": "bda27e34-0fbc-43fd-80b3-b758cc72006b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 train_loss= 0.79272 train_acc= 0.00287 val_roc= 0.92624 val_ap= 0.92429 time= 0.82190\n",
            "Epoch: 0002 train_loss= 0.74811 train_acc= 0.00213 val_roc= 0.92923 val_ap= 0.92639 time= 0.46518\n",
            "Epoch: 0003 train_loss= 0.69017 train_acc= 0.00213 val_roc= 0.93304 val_ap= 0.92915 time= 0.44471\n",
            "Epoch: 0004 train_loss= 0.73434 train_acc= 0.00213 val_roc= 0.93542 val_ap= 0.93099 time= 0.45724\n",
            "Epoch: 0005 train_loss= 0.70578 train_acc= 0.00213 val_roc= 0.93762 val_ap= 0.93274 time= 0.44090\n",
            "Epoch: 0006 train_loss= 0.68404 train_acc= 0.00213 val_roc= 0.93997 val_ap= 0.93478 time= 0.45143\n",
            "Epoch: 0007 train_loss= 0.69244 train_acc= 0.00213 val_roc= 0.94081 val_ap= 0.93562 time= 0.44639\n",
            "Epoch: 0008 train_loss= 0.70248 train_acc= 0.00213 val_roc= 0.94081 val_ap= 0.93551 time= 0.44890\n",
            "Epoch: 0009 train_loss= 0.70215 train_acc= 0.00213 val_roc= 0.94062 val_ap= 0.93531 time= 0.46455\n",
            "Epoch: 0010 train_loss= 0.69347 train_acc= 0.00213 val_roc= 0.94050 val_ap= 0.93525 time= 0.43715\n",
            "Epoch: 0011 train_loss= 0.68331 train_acc= 0.00213 val_roc= 0.94053 val_ap= 0.93523 time= 0.48863\n",
            "Epoch: 0012 train_loss= 0.68008 train_acc= 0.00213 val_roc= 0.94018 val_ap= 0.93501 time= 0.43139\n",
            "Epoch: 0013 train_loss= 0.68545 train_acc= 0.00213 val_roc= 0.93995 val_ap= 0.93504 time= 0.45776\n",
            "Epoch: 0014 train_loss= 0.68942 train_acc= 0.00213 val_roc= 0.93965 val_ap= 0.93494 time= 0.43505\n",
            "Epoch: 0015 train_loss= 0.68515 train_acc= 0.00213 val_roc= 0.93953 val_ap= 0.93472 time= 0.46582\n",
            "Epoch: 0016 train_loss= 0.67801 train_acc= 0.00213 val_roc= 0.93893 val_ap= 0.93413 time= 0.44569\n",
            "Epoch: 0017 train_loss= 0.67473 train_acc= 0.00213 val_roc= 0.93792 val_ap= 0.93310 time= 0.44443\n",
            "Epoch: 0018 train_loss= 0.67544 train_acc= 0.00213 val_roc= 0.93658 val_ap= 0.93144 time= 0.47304\n",
            "Epoch: 0019 train_loss= 0.67650 train_acc= 0.00213 val_roc= 0.93514 val_ap= 0.92956 time= 0.45212\n",
            "Epoch: 0020 train_loss= 0.67559 train_acc= 0.00213 val_roc= 0.93443 val_ap= 0.92826 time= 0.46184\n",
            "Epoch: 0021 train_loss= 0.67198 train_acc= 0.00213 val_roc= 0.93447 val_ap= 0.92845 time= 0.46113\n",
            "Epoch: 0022 train_loss= 0.66722 train_acc= 0.00214 val_roc= 0.93560 val_ap= 0.92944 time= 0.45644\n",
            "Epoch: 0023 train_loss= 0.66376 train_acc= 0.00218 val_roc= 0.93621 val_ap= 0.92970 time= 0.43777\n",
            "Epoch: 0024 train_loss= 0.66246 train_acc= 0.00237 val_roc= 0.93630 val_ap= 0.92936 time= 0.43247\n",
            "Epoch: 0025 train_loss= 0.66158 train_acc= 0.00272 val_roc= 0.93523 val_ap= 0.92739 time= 0.46492\n",
            "Epoch: 0026 train_loss= 0.65886 train_acc= 0.00456 val_roc= 0.93135 val_ap= 0.92287 time= 0.49352\n",
            "Epoch: 0027 train_loss= 0.65412 train_acc= 0.02158 val_roc= 0.92511 val_ap= 0.91978 time= 0.50011\n",
            "Epoch: 0028 train_loss= 0.64909 train_acc= 0.05515 val_roc= 0.91672 val_ap= 0.91670 time= 0.46868\n",
            "Epoch: 0029 train_loss= 0.64507 train_acc= 0.08144 val_roc= 0.90930 val_ap= 0.91159 time= 0.46433\n",
            "Epoch: 0030 train_loss= 0.64164 train_acc= 0.09880 val_roc= 0.90341 val_ap= 0.90743 time= 0.43337\n",
            "Epoch: 0031 train_loss= 0.63814 train_acc= 0.11346 val_roc= 0.89962 val_ap= 0.90415 time= 0.47056\n",
            "Epoch: 0032 train_loss= 0.63527 train_acc= 0.12329 val_roc= 0.89677 val_ap= 0.90275 time= 0.83871\n",
            "Epoch: 0033 train_loss= 0.63366 train_acc= 0.12958 val_roc= 0.89370 val_ap= 0.89974 time= 0.95773\n",
            "Epoch: 0034 train_loss= 0.63247 train_acc= 0.13647 val_roc= 0.89139 val_ap= 0.89772 time= 0.93710\n",
            "Epoch: 0035 train_loss= 0.63075 train_acc= 0.14402 val_roc= 0.88873 val_ap= 0.89361 time= 0.71344\n",
            "Epoch: 0036 train_loss= 0.62892 train_acc= 0.15083 val_roc= 0.88790 val_ap= 0.89230 time= 0.80185\n",
            "Epoch: 0037 train_loss= 0.62768 train_acc= 0.15704 val_roc= 0.88852 val_ap= 0.89271 time= 0.59756\n",
            "Epoch: 0038 train_loss= 0.62661 train_acc= 0.15998 val_roc= 0.89208 val_ap= 0.89479 time= 1.04023\n",
            "Epoch: 0039 train_loss= 0.62506 train_acc= 0.16022 val_roc= 0.89483 val_ap= 0.89691 time= 1.07920\n",
            "Epoch: 0040 train_loss= 0.62325 train_acc= 0.15927 val_roc= 0.89871 val_ap= 0.89902 time= 0.43215\n",
            "Epoch: 0041 train_loss= 0.62167 train_acc= 0.15820 val_roc= 0.90308 val_ap= 0.90161 time= 0.43538\n",
            "Epoch: 0042 train_loss= 0.62028 train_acc= 0.15786 val_roc= 0.90643 val_ap= 0.90358 time= 0.46543\n",
            "Epoch: 0043 train_loss= 0.61870 train_acc= 0.15821 val_roc= 0.90944 val_ap= 0.90396 time= 0.44209\n",
            "Epoch: 0044 train_loss= 0.61690 train_acc= 0.15862 val_roc= 0.91203 val_ap= 0.90433 time= 0.46290\n",
            "Epoch: 0045 train_loss= 0.61516 train_acc= 0.15870 val_roc= 0.91300 val_ap= 0.90429 time= 0.44769\n",
            "Epoch: 0046 train_loss= 0.61348 train_acc= 0.15882 val_roc= 0.91473 val_ap= 0.90557 time= 0.46162\n",
            "Epoch: 0047 train_loss= 0.61158 train_acc= 0.15916 val_roc= 0.91635 val_ap= 0.90601 time= 0.45797\n",
            "Epoch: 0048 train_loss= 0.60940 train_acc= 0.15944 val_roc= 0.91869 val_ap= 0.90728 time= 0.49611\n",
            "Epoch: 0049 train_loss= 0.60705 train_acc= 0.15976 val_roc= 0.92137 val_ap= 0.90883 time= 0.47126\n",
            "Epoch: 0050 train_loss= 0.60448 train_acc= 0.16053 val_roc= 0.92222 val_ap= 0.90976 time= 0.47128\n",
            "Epoch: 0051 train_loss= 0.60147 train_acc= 0.16205 val_roc= 0.92285 val_ap= 0.91090 time= 0.44149\n",
            "Epoch: 0052 train_loss= 0.59801 train_acc= 0.16471 val_roc= 0.92310 val_ap= 0.91194 time= 0.45476\n",
            "Epoch: 0053 train_loss= 0.59428 train_acc= 0.16842 val_roc= 0.92194 val_ap= 0.91108 time= 0.44441\n",
            "Epoch: 0054 train_loss= 0.59031 train_acc= 0.17381 val_roc= 0.92127 val_ap= 0.91081 time= 0.43171\n",
            "Epoch: 0055 train_loss= 0.58602 train_acc= 0.18149 val_roc= 0.92026 val_ap= 0.90978 time= 0.47554\n",
            "Epoch: 0056 train_loss= 0.58134 train_acc= 0.19172 val_roc= 0.91899 val_ap= 0.90937 time= 0.43922\n",
            "Epoch: 0057 train_loss= 0.57623 train_acc= 0.20521 val_roc= 0.91718 val_ap= 0.90760 time= 0.50803\n",
            "Epoch: 0058 train_loss= 0.57055 train_acc= 0.22351 val_roc= 0.91476 val_ap= 0.90565 time= 0.47773\n",
            "Epoch: 0059 train_loss= 0.56436 train_acc= 0.24701 val_roc= 0.91194 val_ap= 0.90354 time= 0.49792\n",
            "Epoch: 0060 train_loss= 0.55796 train_acc= 0.27436 val_roc= 0.91027 val_ap= 0.89998 time= 0.51400\n",
            "Epoch: 0061 train_loss= 0.55156 train_acc= 0.30313 val_roc= 0.90486 val_ap= 0.89545 time= 0.45984\n",
            "Epoch: 0062 train_loss= 0.54533 train_acc= 0.33208 val_roc= 0.89883 val_ap= 0.89115 time= 0.44889\n",
            "Epoch: 0063 train_loss= 0.53955 train_acc= 0.35972 val_roc= 0.89118 val_ap= 0.88719 time= 0.43799\n",
            "Epoch: 0064 train_loss= 0.53456 train_acc= 0.38618 val_roc= 0.88036 val_ap= 0.87886 time= 0.46781\n",
            "Epoch: 0065 train_loss= 0.53055 train_acc= 0.41109 val_roc= 0.86592 val_ap= 0.87075 time= 0.47463\n",
            "Epoch: 0066 train_loss= 0.52752 train_acc= 0.43417 val_roc= 0.85392 val_ap= 0.86322 time= 0.49018\n",
            "Epoch: 0067 train_loss= 0.52539 train_acc= 0.45364 val_roc= 0.84558 val_ap= 0.85825 time= 0.45505\n",
            "Epoch: 0068 train_loss= 0.52368 train_acc= 0.46730 val_roc= 0.84241 val_ap= 0.85566 time= 0.44624\n",
            "Epoch: 0069 train_loss= 0.52206 train_acc= 0.47572 val_roc= 0.84463 val_ap= 0.85722 time= 0.44198\n",
            "Epoch: 0070 train_loss= 0.52047 train_acc= 0.47860 val_roc= 0.84625 val_ap= 0.85958 time= 0.46087\n",
            "Epoch: 0071 train_loss= 0.51907 train_acc= 0.48079 val_roc= 0.84511 val_ap= 0.85993 time= 0.46415\n",
            "Epoch: 0072 train_loss= 0.51748 train_acc= 0.48572 val_roc= 0.84255 val_ap= 0.86202 time= 0.50198\n",
            "Epoch: 0073 train_loss= 0.51588 train_acc= 0.49252 val_roc= 0.84026 val_ap= 0.86200 time= 0.49455\n",
            "Epoch: 0074 train_loss= 0.51469 train_acc= 0.49918 val_roc= 0.84269 val_ap= 0.86582 time= 0.44118\n",
            "Epoch: 0075 train_loss= 0.51358 train_acc= 0.49936 val_roc= 0.84726 val_ap= 0.87030 time= 0.46538\n",
            "Epoch: 0076 train_loss= 0.51270 train_acc= 0.49394 val_roc= 0.85001 val_ap= 0.87163 time= 0.83529\n",
            "Epoch: 0077 train_loss= 0.51204 train_acc= 0.48918 val_roc= 0.85022 val_ap= 0.87124 time= 0.43844\n",
            "Epoch: 0078 train_loss= 0.51134 train_acc= 0.48835 val_roc= 0.84962 val_ap= 0.87089 time= 0.45027\n",
            "Epoch: 0079 train_loss= 0.51069 train_acc= 0.48987 val_roc= 0.85022 val_ap= 0.87127 time= 0.44581\n",
            "Epoch: 0080 train_loss= 0.50988 train_acc= 0.48997 val_roc= 0.85274 val_ap= 0.87205 time= 0.44926\n",
            "Epoch: 0081 train_loss= 0.50897 train_acc= 0.48709 val_roc= 0.85545 val_ap= 0.87352 time= 0.45855\n",
            "Epoch: 0082 train_loss= 0.50800 train_acc= 0.48466 val_roc= 0.85658 val_ap= 0.87404 time= 0.43484\n",
            "Epoch: 0083 train_loss= 0.50690 train_acc= 0.48528 val_roc= 0.85723 val_ap= 0.87397 time= 0.46231\n",
            "Epoch: 0084 train_loss= 0.50590 train_acc= 0.48764 val_roc= 0.85850 val_ap= 0.87484 time= 0.44763\n",
            "Epoch: 0085 train_loss= 0.50490 train_acc= 0.48875 val_roc= 0.85898 val_ap= 0.87281 time= 0.43984\n",
            "Epoch: 0086 train_loss= 0.50399 train_acc= 0.48913 val_roc= 0.85801 val_ap= 0.87165 time= 0.44827\n",
            "Epoch: 0087 train_loss= 0.50328 train_acc= 0.49091 val_roc= 0.85605 val_ap= 0.86981 time= 0.67218\n",
            "Epoch: 0088 train_loss= 0.50263 train_acc= 0.49429 val_roc= 0.85466 val_ap= 0.86881 time= 0.93433\n",
            "Epoch: 0089 train_loss= 0.50206 train_acc= 0.49607 val_roc= 0.85489 val_ap= 0.86867 time= 0.47064\n",
            "Epoch: 0090 train_loss= 0.50150 train_acc= 0.49478 val_roc= 0.85570 val_ap= 0.86775 time= 0.45384\n",
            "Epoch: 0091 train_loss= 0.50096 train_acc= 0.49298 val_roc= 0.85408 val_ap= 0.86620 time= 0.44658\n",
            "Epoch: 0092 train_loss= 0.50035 train_acc= 0.49437 val_roc= 0.85246 val_ap= 0.86600 time= 0.44761\n",
            "Epoch: 0093 train_loss= 0.49977 train_acc= 0.49683 val_roc= 0.85249 val_ap= 0.86527 time= 0.45545\n",
            "Epoch: 0094 train_loss= 0.49919 train_acc= 0.49656 val_roc= 0.85369 val_ap= 0.86519 time= 0.45136\n",
            "Epoch: 0095 train_loss= 0.49865 train_acc= 0.49416 val_roc= 0.85443 val_ap= 0.86637 time= 0.48751\n",
            "Epoch: 0096 train_loss= 0.49816 train_acc= 0.49313 val_roc= 0.85369 val_ap= 0.86571 time= 0.45746\n",
            "Epoch: 0097 train_loss= 0.49767 train_acc= 0.49469 val_roc= 0.85369 val_ap= 0.86753 time= 0.46525\n",
            "Epoch: 0098 train_loss= 0.49718 train_acc= 0.49555 val_roc= 0.85473 val_ap= 0.86694 time= 0.44926\n",
            "Epoch: 0099 train_loss= 0.49666 train_acc= 0.49452 val_roc= 0.85491 val_ap= 0.86760 time= 0.46310\n",
            "Epoch: 0100 train_loss= 0.49611 train_acc= 0.49408 val_roc= 0.85413 val_ap= 0.86709 time= 0.45909\n",
            "Epoch: 0101 train_loss= 0.49553 train_acc= 0.49583 val_roc= 0.85385 val_ap= 0.86700 time= 0.48853\n",
            "Epoch: 0102 train_loss= 0.49495 train_acc= 0.49698 val_roc= 0.85452 val_ap= 0.86806 time= 0.49572\n",
            "Epoch: 0103 train_loss= 0.49435 train_acc= 0.49654 val_roc= 0.85431 val_ap= 0.86801 time= 0.45328\n",
            "Epoch: 0104 train_loss= 0.49380 train_acc= 0.49738 val_roc= 0.85281 val_ap= 0.86686 time= 0.45490\n",
            "Epoch: 0105 train_loss= 0.49329 train_acc= 0.49933 val_roc= 0.85295 val_ap= 0.86711 time= 0.44626\n",
            "Epoch: 0106 train_loss= 0.49283 train_acc= 0.49934 val_roc= 0.85316 val_ap= 0.86769 time= 0.46609\n",
            "Epoch: 0107 train_loss= 0.49242 train_acc= 0.49878 val_roc= 0.85200 val_ap= 0.86699 time= 0.45665\n",
            "Epoch: 0108 train_loss= 0.49202 train_acc= 0.49977 val_roc= 0.85122 val_ap= 0.86628 time= 0.46218\n",
            "Epoch: 0109 train_loss= 0.49162 train_acc= 0.50051 val_roc= 0.85198 val_ap= 0.86757 time= 0.44857\n",
            "Epoch: 0110 train_loss= 0.49121 train_acc= 0.49976 val_roc= 0.85196 val_ap= 0.86789 time= 0.45203\n",
            "Epoch: 0111 train_loss= 0.49078 train_acc= 0.49958 val_roc= 0.85115 val_ap= 0.86760 time= 0.45247\n",
            "Epoch: 0112 train_loss= 0.49035 train_acc= 0.50006 val_roc= 0.85105 val_ap= 0.86781 time= 0.43668\n",
            "Epoch: 0113 train_loss= 0.48993 train_acc= 0.49949 val_roc= 0.85089 val_ap= 0.86784 time= 0.46584\n",
            "Epoch: 0114 train_loss= 0.48952 train_acc= 0.49915 val_roc= 0.85008 val_ap= 0.86719 time= 0.43586\n",
            "Epoch: 0115 train_loss= 0.48913 train_acc= 0.49976 val_roc= 0.85011 val_ap= 0.86749 time= 0.45886\n",
            "Epoch: 0116 train_loss= 0.48875 train_acc= 0.49913 val_roc= 0.85013 val_ap= 0.86781 time= 0.55675\n",
            "Epoch: 0117 train_loss= 0.48839 train_acc= 0.49874 val_roc= 0.84860 val_ap= 0.86672 time= 0.76449\n",
            "Epoch: 0118 train_loss= 0.48802 train_acc= 0.49951 val_roc= 0.84814 val_ap= 0.86625 time= 0.60463\n",
            "Epoch: 0119 train_loss= 0.48766 train_acc= 0.49965 val_roc= 0.84775 val_ap= 0.86598 time= 0.44894\n",
            "Epoch: 0120 train_loss= 0.48731 train_acc= 0.49925 val_roc= 0.84645 val_ap= 0.86511 time= 0.45957\n",
            "Epoch: 0121 train_loss= 0.48696 train_acc= 0.50000 val_roc= 0.84627 val_ap= 0.86511 time= 0.44849\n",
            "Epoch: 0122 train_loss= 0.48661 train_acc= 0.49971 val_roc= 0.84574 val_ap= 0.86470 time= 0.45428\n",
            "Epoch: 0123 train_loss= 0.48626 train_acc= 0.49980 val_roc= 0.84474 val_ap= 0.86406 time= 0.43622\n",
            "Epoch: 0124 train_loss= 0.48592 train_acc= 0.50020 val_roc= 0.84477 val_ap= 0.86435 time= 0.45009\n",
            "Epoch: 0125 train_loss= 0.48559 train_acc= 0.49993 val_roc= 0.84345 val_ap= 0.86341 time= 0.43983\n",
            "Epoch: 0126 train_loss= 0.48525 train_acc= 0.50035 val_roc= 0.84315 val_ap= 0.86334 time= 0.48241\n",
            "Epoch: 0127 train_loss= 0.48492 train_acc= 0.50029 val_roc= 0.84273 val_ap= 0.86316 time= 0.50512\n",
            "Epoch: 0128 train_loss= 0.48459 train_acc= 0.49987 val_roc= 0.84128 val_ap= 0.86230 time= 0.46003\n",
            "Epoch: 0129 train_loss= 0.48427 train_acc= 0.50034 val_roc= 0.84070 val_ap= 0.86213 time= 0.45348\n",
            "Epoch: 0130 train_loss= 0.48395 train_acc= 0.50030 val_roc= 0.84021 val_ap= 0.86223 time= 0.45139\n",
            "Epoch: 0131 train_loss= 0.48363 train_acc= 0.50004 val_roc= 0.83901 val_ap= 0.86175 time= 0.45826\n",
            "Epoch: 0132 train_loss= 0.48332 train_acc= 0.50032 val_roc= 0.83830 val_ap= 0.86163 time= 0.44144\n",
            "Epoch: 0133 train_loss= 0.48301 train_acc= 0.50016 val_roc= 0.83765 val_ap= 0.86129 time= 0.46445\n",
            "Epoch: 0134 train_loss= 0.48271 train_acc= 0.50013 val_roc= 0.83631 val_ap= 0.86066 time= 0.43915\n",
            "Epoch: 0135 train_loss= 0.48240 train_acc= 0.50047 val_roc= 0.83550 val_ap= 0.86024 time= 0.45188\n",
            "Epoch: 0136 train_loss= 0.48210 train_acc= 0.50025 val_roc= 0.83446 val_ap= 0.85974 time= 0.45376\n",
            "Epoch: 0137 train_loss= 0.48180 train_acc= 0.50049 val_roc= 0.83356 val_ap= 0.85943 time= 0.43700\n",
            "Epoch: 0138 train_loss= 0.48151 train_acc= 0.50070 val_roc= 0.83279 val_ap= 0.85902 time= 0.45790\n",
            "Epoch: 0139 train_loss= 0.48121 train_acc= 0.50060 val_roc= 0.83159 val_ap= 0.85851 time= 0.42808\n",
            "Epoch: 0140 train_loss= 0.48091 train_acc= 0.50085 val_roc= 0.83067 val_ap= 0.85793 time= 0.45471\n",
            "Epoch: 0141 train_loss= 0.48062 train_acc= 0.50084 val_roc= 0.82947 val_ap= 0.85729 time= 0.44642\n",
            "Epoch: 0142 train_loss= 0.48032 train_acc= 0.50093 val_roc= 0.82861 val_ap= 0.85691 time= 0.44357\n",
            "Epoch: 0143 train_loss= 0.48003 train_acc= 0.50097 val_roc= 0.82702 val_ap= 0.85606 time= 0.45207\n",
            "Epoch: 0144 train_loss= 0.47974 train_acc= 0.50129 val_roc= 0.82611 val_ap= 0.85581 time= 0.44814\n",
            "Epoch: 0145 train_loss= 0.47945 train_acc= 0.50125 val_roc= 0.82535 val_ap= 0.85550 time= 0.45756\n",
            "Epoch: 0146 train_loss= 0.47916 train_acc= 0.50132 val_roc= 0.82387 val_ap= 0.85460 time= 0.44791\n",
            "Epoch: 0147 train_loss= 0.47887 train_acc= 0.50150 val_roc= 0.82304 val_ap= 0.85406 time= 0.46072\n",
            "Epoch: 0148 train_loss= 0.47858 train_acc= 0.50139 val_roc= 0.82230 val_ap= 0.85390 time= 0.44514\n",
            "Epoch: 0149 train_loss= 0.47828 train_acc= 0.50141 val_roc= 0.82105 val_ap= 0.85334 time= 0.45945\n",
            "Epoch: 0150 train_loss= 0.47799 train_acc= 0.50161 val_roc= 0.82022 val_ap= 0.85308 time= 0.45522\n",
            "Epoch: 0151 train_loss= 0.47769 train_acc= 0.50168 val_roc= 0.81980 val_ap= 0.85294 time= 0.44293\n",
            "Epoch: 0152 train_loss= 0.47739 train_acc= 0.50179 val_roc= 0.81932 val_ap= 0.85278 time= 0.44569\n",
            "Epoch: 0153 train_loss= 0.47709 train_acc= 0.50182 val_roc= 0.81867 val_ap= 0.85265 time= 0.43124\n",
            "Epoch: 0154 train_loss= 0.47679 train_acc= 0.50221 val_roc= 0.81934 val_ap= 0.85342 time= 0.44100\n",
            "Epoch: 0155 train_loss= 0.47648 train_acc= 0.50159 val_roc= 0.81664 val_ap= 0.85172 time= 0.43158\n",
            "Epoch: 0156 train_loss= 0.47618 train_acc= 0.50319 val_roc= 0.81913 val_ap= 0.85369 time= 0.43310\n",
            "Epoch: 0157 train_loss= 0.47589 train_acc= 0.50130 val_roc= 0.81407 val_ap= 0.85016 time= 0.44797\n",
            "Epoch: 0158 train_loss= 0.47560 train_acc= 0.50442 val_roc= 0.81980 val_ap= 0.85465 time= 0.45333\n",
            "Epoch: 0159 train_loss= 0.47534 train_acc= 0.50057 val_roc= 0.81137 val_ap= 0.84854 time= 0.43711\n",
            "Epoch: 0160 train_loss= 0.47504 train_acc= 0.50562 val_roc= 0.81881 val_ap= 0.85415 time= 0.44549\n",
            "Epoch: 0161 train_loss= 0.47466 train_acc= 0.50129 val_roc= 0.81275 val_ap= 0.84984 time= 0.43987\n",
            "Epoch: 0162 train_loss= 0.47423 train_acc= 0.50484 val_roc= 0.81442 val_ap= 0.85099 time= 0.44885\n",
            "Epoch: 0163 train_loss= 0.47383 train_acc= 0.50390 val_roc= 0.81553 val_ap= 0.85191 time= 0.46948\n",
            "Epoch: 0164 train_loss= 0.47350 train_acc= 0.50328 val_roc= 0.81104 val_ap= 0.84905 time= 0.46409\n",
            "Epoch: 0165 train_loss= 0.47318 train_acc= 0.50615 val_roc= 0.81634 val_ap= 0.85286 time= 0.43658\n",
            "Epoch: 0166 train_loss= 0.47283 train_acc= 0.50305 val_roc= 0.81148 val_ap= 0.84948 time= 0.44638\n",
            "Epoch: 0167 train_loss= 0.47239 train_acc= 0.50661 val_roc= 0.81370 val_ap= 0.85121 time= 0.45833\n",
            "Epoch: 0168 train_loss= 0.47194 train_acc= 0.50523 val_roc= 0.81435 val_ap= 0.85187 time= 0.45425\n",
            "Epoch: 0169 train_loss= 0.47155 train_acc= 0.50514 val_roc= 0.81158 val_ap= 0.85122 time= 0.44864\n",
            "Epoch: 0170 train_loss= 0.47118 train_acc= 0.50745 val_roc= 0.81534 val_ap= 0.85264 time= 0.45507\n",
            "Epoch: 0171 train_loss= 0.47079 train_acc= 0.50489 val_roc= 0.81130 val_ap= 0.85124 time= 0.43581\n",
            "Epoch: 0172 train_loss= 0.47034 train_acc= 0.50808 val_roc= 0.81444 val_ap= 0.85374 time= 0.45228\n",
            "Epoch: 0173 train_loss= 0.46987 train_acc= 0.50639 val_roc= 0.81354 val_ap= 0.85328 time= 0.50173\n",
            "Epoch: 0174 train_loss= 0.46943 train_acc= 0.50751 val_roc= 0.81292 val_ap= 0.85289 time= 0.69191\n",
            "Epoch: 0175 train_loss= 0.46902 train_acc= 0.50874 val_roc= 0.81504 val_ap= 0.85472 time= 0.70398\n",
            "Epoch: 0176 train_loss= 0.46863 train_acc= 0.50723 val_roc= 0.81204 val_ap= 0.85266 time= 0.66349\n",
            "Epoch: 0177 train_loss= 0.46824 train_acc= 0.51002 val_roc= 0.81534 val_ap= 0.85517 time= 0.69308\n",
            "Epoch: 0178 train_loss= 0.46784 train_acc= 0.50783 val_roc= 0.81333 val_ap= 0.85374 time= 0.68433\n",
            "Epoch: 0179 train_loss= 0.46745 train_acc= 0.51005 val_roc= 0.81513 val_ap= 0.85528 time= 0.71381\n",
            "Epoch: 0180 train_loss= 0.46708 train_acc= 0.50906 val_roc= 0.81504 val_ap= 0.85506 time= 0.42390\n",
            "Epoch: 0181 train_loss= 0.46674 train_acc= 0.50954 val_roc= 0.81403 val_ap= 0.85567 time= 0.43823\n",
            "Epoch: 0182 train_loss= 0.46644 train_acc= 0.51032 val_roc= 0.81504 val_ap= 0.85571 time= 0.43728\n",
            "Epoch: 0183 train_loss= 0.46616 train_acc= 0.50895 val_roc= 0.81248 val_ap= 0.85513 time= 0.46677\n",
            "Epoch: 0184 train_loss= 0.46590 train_acc= 0.51092 val_roc= 0.81474 val_ap= 0.85434 time= 0.45995\n",
            "Epoch: 0185 train_loss= 0.46564 train_acc= 0.50865 val_roc= 0.81146 val_ap= 0.85547 time= 0.46173\n",
            "Epoch: 0186 train_loss= 0.46539 train_acc= 0.51106 val_roc= 0.81361 val_ap= 0.85562 time= 0.43629\n",
            "Epoch: 0187 train_loss= 0.46513 train_acc= 0.50880 val_roc= 0.81160 val_ap= 0.85548 time= 0.47536\n",
            "Epoch: 0188 train_loss= 0.46487 train_acc= 0.51074 val_roc= 0.81238 val_ap= 0.85545 time= 0.43876\n",
            "Epoch: 0189 train_loss= 0.46460 train_acc= 0.50940 val_roc= 0.81134 val_ap= 0.85593 time= 0.44587\n",
            "Epoch: 0190 train_loss= 0.46434 train_acc= 0.50999 val_roc= 0.81077 val_ap= 0.85569 time= 0.44185\n",
            "Epoch: 0191 train_loss= 0.46408 train_acc= 0.51025 val_roc= 0.81137 val_ap= 0.85531 time= 0.44783\n",
            "Epoch: 0192 train_loss= 0.46381 train_acc= 0.50953 val_roc= 0.80954 val_ap= 0.85391 time= 0.44418\n",
            "Epoch: 0193 train_loss= 0.46354 train_acc= 0.51093 val_roc= 0.81102 val_ap= 0.85542 time= 0.44802\n",
            "Epoch: 0194 train_loss= 0.46327 train_acc= 0.50940 val_roc= 0.80843 val_ap= 0.85360 time= 0.44796\n",
            "Epoch: 0195 train_loss= 0.46299 train_acc= 0.51130 val_roc= 0.81021 val_ap= 0.85529 time= 0.44867\n",
            "Epoch: 0196 train_loss= 0.46270 train_acc= 0.50968 val_roc= 0.80866 val_ap= 0.85407 time= 0.43480\n",
            "Epoch: 0197 train_loss= 0.46242 train_acc= 0.51132 val_roc= 0.80993 val_ap= 0.85571 time= 0.45257\n",
            "Epoch: 0198 train_loss= 0.46215 train_acc= 0.51005 val_roc= 0.80850 val_ap= 0.85443 time= 0.43276\n",
            "Epoch: 0199 train_loss= 0.46189 train_acc= 0.51178 val_roc= 0.80963 val_ap= 0.85580 time= 0.44818\n",
            "Epoch: 0200 train_loss= 0.46164 train_acc= 0.51022 val_roc= 0.80758 val_ap= 0.85404 time= 0.45436\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.8729428624260356\n",
            "Test AP score: 0.9113332725960389\n"
          ]
        }
      ],
      "source": [
        "## Train model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: dropout})\n",
        "    # Run single weight update\n",
        "    outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
        "\n",
        "    # Compute average loss\n",
        "    avg_cost = outs[1]\n",
        "    avg_accuracy = outs[2]\n",
        "\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
        "    val_roc_score.append(roc_curr)\n",
        "\n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
        "          \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
        "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
        "print('Test ROC score: ' + str(roc_score))\n",
        "print('Test AP score: ' + str(ap_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :)\n"
      ],
      "metadata": {
        "id": "hE4aW2Atfh0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o549vlS0m-P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqv_JBXbu-_W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6eQa-hDvIDi"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Content_Top1-BERT.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R3CAEqayACr"
      },
      "outputs": [],
      "source": [
        "data = list(objecta.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2qBq1UG0l5G"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHAybEIq0ztz"
      },
      "outputs": [],
      "source": [
        "feats = tmp.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kHEfVUb2KH8"
      },
      "outputs": [],
      "source": [
        "features = sp.lil_matrix(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-UEmNGyQsNt"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOIKUe00Q3_6"
      },
      "outputs": [],
      "source": [
        "nodeslist = tmp.columns.values\n",
        "# np.sum(nodeslist == 26285)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgxJ1J5tRdQR"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Indexes_Top1-byTRM-Dic.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3BDW-OORkGj"
      },
      "outputs": [],
      "source": [
        "edjs=[]\n",
        "for idx, targets in objecta.items():\n",
        "  target_str = targets.split(',')\n",
        "  for j in target_str:\n",
        "    edjs.append((idx, int(j)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYdK7XLmRpIk"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edjs)\n",
        "A = nx.adjacency_matrix(G, nodelist=nodeslist)\n",
        "degrees = [node for (node, val) in G.degree() if val>5]\n",
        "A = nx.adjacency_matrix(G, nodelist=degrees)\n",
        "A.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eB7YZ0tVssx"
      },
      "outputs": [],
      "source": [
        "G.add_edges_from(edjs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdO2LYfeWlkI"
      },
      "outputs": [],
      "source": [
        "A = nx.adjacency_matrix(G, nodelist=nodeslist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWWHDUlcWtOr"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# np.sum(A[65,:].toarray()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EImA_kSnhtXD"
      },
      "outputs": [],
      "source": [
        "degrees = [node for (node, val) in G.degree() if val>5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zABQ-CaXig6k"
      },
      "outputs": [],
      "source": [
        "A = nx.adjacency_matrix(G, nodelist=degrees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR-4IDKZ_Wuy"
      },
      "outputs": [],
      "source": [
        "tmp = np.random.rand(2072, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqRl-hzw_pMd"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x): \n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Predict on test set of edges\n",
        "adj_tmp = np.dot(tmp, tmp.T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "\n",
        "x = convert_sparse_matrix_to_sparse_tensor(adj_label)"
      ],
      "metadata": {
        "id": "tAkmm-py5ZZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "9ed0c671-a279-4b5d-ecc1-b7a2ba322fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-92cf5248fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sparse_matrix_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-92cf5248fa55>\u001b[0m in \u001b[0;36mconvert_sparse_matrix_to_sparse_tensor\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_sparse_matrix_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tocoo'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDCC3SowEG5P"
      },
      "outputs": [],
      "source": [
        "def get_roc_score_a(edges_pos, edges_neg, emb=None):\n",
        "    if emb is None:\n",
        "        # feed_dict.update({placeholders['dropout']: 0})\n",
        "        emb = tmp\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klulqViA_3Wq"
      },
      "outputs": [],
      "source": [
        "correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(adj_tmp), 0.5), tf.int32),\n",
        "                                           tf.cast(adj_label.todense(), tf.int32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XurHgBQKDYip"
      },
      "outputs": [],
      "source": [
        "adj_label = adj_train + sp.eye(adj_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5byLKFHEx2-"
      },
      "outputs": [],
      "source": [
        "roc_curr, ap_curr = get_roc_score_a(val_edges, val_edges_false)\n",
        "print(roc_curr, ap_curr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_pjsEiLE7tu"
      },
      "outputs": [],
      "source": [
        "roc_curr, ap_curr = get_roc_score_a(test_edges, test_edges_false)\n",
        "print(roc_curr, ap_curr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E1CcRpGCX3De",
        "3kPmH5zMYj6Q",
        "1G_VlvyFZFWv",
        "GFs3RJdIZ995",
        "YgNYjfErZiEV",
        "LxOUv5YHYJ19",
        "fBL84Q2LZsiR"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}