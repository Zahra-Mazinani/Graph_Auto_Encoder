{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahra-Mazinani/Graph_Auto_Encoder/blob/main/GAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "E1CcRpGCX3De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1fQJjL4LYWf",
        "outputId": "a5304759-cd6c-4914-a49e-54f249ac4941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gae' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tkipf/gae.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2DKBYKfWLjdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbd9664-b5eb-4029-e6a2-938edb392398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing gae.egg-info/PKG-INFO\n",
            "writing dependency_links to gae.egg-info/dependency_links.txt\n",
            "writing requirements to gae.egg-info/requires.txt\n",
            "writing top-level names to gae.egg-info/top_level.txt\n",
            "writing manifest file 'gae.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/gae-0.0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing gae-0.0.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Copying gae-0.0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "gae 0.0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Processing dependencies for gae==0.0.1\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.3\n",
            "Best match: networkx 2.6.3\n",
            "Adding networkx 2.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow==2.9.2\n",
            "Best match: tensorflow 2.9.2\n",
            "Adding tensorflow 2.9.2 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing import_pb_to_tensorboard script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for flatbuffers==1.12\n",
            "Best match: flatbuffers 1.12\n",
            "Adding flatbuffers 1.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opt-einsum==3.3.0\n",
            "Best match: opt-einsum 3.3.0\n",
            "Adding opt-einsum 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for h5py==3.1.0\n",
            "Best match: h5py 3.1.0\n",
            "Adding h5py 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==2.0.1\n",
            "Best match: termcolor 2.0.1\n",
            "Adding termcolor 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-io-gcs-filesystem==0.27.0\n",
            "Best match: tensorflow-io-gcs-filesystem 0.27.0\n",
            "Adding tensorflow-io-gcs-filesystem 0.27.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-estimator==2.9.0\n",
            "Best match: tensorflow-estimator 2.9.0\n",
            "Adding tensorflow-estimator 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wrapt==1.14.1\n",
            "Best match: wrapt 1.14.1\n",
            "Adding wrapt 1.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.49.1\n",
            "Best match: grpcio 1.49.1\n",
            "Adding grpcio 1.49.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for libclang==14.0.6\n",
            "Best match: libclang 14.0.6\n",
            "Adding libclang 14.0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gast==0.4.0\n",
            "Best match: gast 0.4.0\n",
            "Adding gast 0.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.9.1\n",
            "Best match: tensorboard 2.9.1\n",
            "Adding tensorboard 2.9.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for keras==2.9.0\n",
            "Best match: keras 2.9.0\n",
            "Adding keras 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cached-property==1.5.2\n",
            "Best match: cached-property 1.5.2\n",
            "Adding cached-property 1.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.9.24\n",
            "Best match: certifi 2022.9.24\n",
            "Adding certifi 2022.9.24 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.13.0\n",
            "Best match: importlib-metadata 4.13.0\n",
            "Adding importlib-metadata 4.13.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.9.0\n",
            "Best match: zipp 3.9.0\n",
            "Adding zipp 3.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.1\n",
            "Best match: oauthlib 3.2.1\n",
            "Adding oauthlib 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for gae==0.0.1\n"
          ]
        }
      ],
      "source": [
        "!python /content/gae/setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "egtdHtZEYBD7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializations"
      ],
      "metadata": {
        "id": "3kPmH5zMYj6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "k_tGZM3fM11T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
        "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010)\n",
        "    initialization.\n",
        "    \"\"\"\n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n",
        "                                maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input data"
      ],
      "metadata": {
        "id": "1G_VlvyFZFWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "kh0JUMJ3fzWd"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index"
      ],
      "metadata": {
        "id": "woM31ouTf2a1"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"data/ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "metadata": {
        "id": "DT6QoeI5ZD0j"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "GFs3RJdIZ995"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "8JFBub93cjhG"
      },
      "outputs": [],
      "source": [
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CZeEkbLCpYqt"
      },
      "outputs": [],
      "source": [
        "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
        "    # construct feed dictionary\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
        "    feed_dict.update({placeholders['adj_orig']: adj})\n",
        "    return feed_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)"
      ],
      "metadata": {
        "id": "XD6OoK30c-Br"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "IxSUBYYdcaQg"
      },
      "outputs": [],
      "source": [
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Layers"
      ],
      "metadata": {
        "id": "YgNYjfErZiEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# global unique layer ID dictionary for layer name assignment\n",
        "_LAYER_UIDS = {}"
      ],
      "metadata": {
        "id": "qLV8gOgGf8zY"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layer_uid(layer_name=''):\n",
        "    \"\"\"Helper function, assigns unique layer IDs\n",
        "    \"\"\"\n",
        "    if layer_name not in _LAYER_UIDS:\n",
        "        _LAYER_UIDS[layer_name] = 1\n",
        "        return 1\n",
        "    else:\n",
        "        _LAYER_UIDS[layer_name] += 1\n",
        "        return _LAYER_UIDS[layer_name]"
      ],
      "metadata": {
        "id": "f8FMscFIf-uF"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
        "    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n",
        "    \"\"\"\n",
        "    noise_shape = [num_nonzero_elems]\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1./keep_prob)"
      ],
      "metadata": {
        "id": "6LVe-UZigCrJ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(object):\n",
        "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
        "\n",
        "    # Properties\n",
        "        name: String, defines the variable scope of the layer.\n",
        "\n",
        "    # Methods\n",
        "        _call(inputs): Defines computation graph of layer\n",
        "            (i.e. takes input, returns output)\n",
        "        __call__(inputs): Wrapper for _call()\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            layer = self.__class__.__name__.lower()\n",
        "            name = layer + '_' + str(get_layer_uid(layer))\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "        self.issparse = False\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            outputs = self._call(inputs)\n",
        "            return outputs"
      ],
      "metadata": {
        "id": "Q_QqoKTygNms"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(Layer):\n",
        "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolution, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = tf.nn.dropout(x, 1-self.dropout)\n",
        "        x = tf.matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "-hqbqd1ygQSX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolutionSparse(Layer):\n",
        "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolutionSparse, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = True\n",
        "        self.features_nonzero = features_nonzero\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
        "        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "JmZoQ9-OgVG3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "wtHW27IUMvic"
      },
      "outputs": [],
      "source": [
        "class InnerProductDecoder(Layer):\n",
        "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
        "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
        "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
        "        x = tf.transpose(inputs)\n",
        "        x = tf.matmul(inputs, x)\n",
        "        x = tf.reshape(x, [-1])\n",
        "        outputs = self.act(x)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "LxOUv5YHYJ19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "DKID7cetnyDO"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            name = self.__class__.__name__.lower()\n",
        "        self.name = name\n",
        "\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "\n",
        "        self.vars = {}\n",
        "\n",
        "    def _build(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\" Wrapper for _build() \"\"\"\n",
        "        with tf.variable_scope(self.name):\n",
        "            self._build()\n",
        "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "        self.vars = {var.name: var for var in variables}\n",
        "\n",
        "    def fit(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "NUpRwgUan07z"
      },
      "outputs": [],
      "source": [
        "class GCNModelAE(Model):\n",
        "    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n",
        "        super(GCNModelAE, self).__init__(**kwargs)\n",
        "\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = num_features\n",
        "        self.features_nonzero = features_nonzero\n",
        "        self.adj = placeholders['adj']\n",
        "        self.dropout = placeholders['dropout']\n",
        "        self.build()\n",
        "\n",
        "    def _build(self):\n",
        "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
        "                                              output_dim=hidden1,\n",
        "                                              adj=self.adj,\n",
        "                                              features_nonzero=self.features_nonzero,\n",
        "                                              act=tf.nn.relu,\n",
        "                                              dropout=self.dropout,\n",
        "                                              logging=self.logging)(self.inputs)\n",
        "\n",
        "        self.embeddings = GraphConvolution(input_dim=hidden1,\n",
        "                                           output_dim=hidden2,\n",
        "                                           adj=self.adj,\n",
        "                                           act=lambda x: x,\n",
        "                                           dropout=self.dropout,\n",
        "                                           logging=self.logging)(self.hidden1)\n",
        "\n",
        "        self.z_mean = self.embeddings\n",
        "\n",
        "        self.reconstructions = InnerProductDecoder(input_dim=hidden2,\n",
        "                                      act=lambda x: x,\n",
        "                                      logging=self.logging)(self.embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimizer"
      ],
      "metadata": {
        "id": "fBL84Q2LZsiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizerAE(object):\n",
        "    def __init__(self, preds, labels, pos_weight, norm):\n",
        "        preds_sub = preds\n",
        "        labels_sub = labels\n",
        "\n",
        "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # Adam Optimizer\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.cost)\n",
        "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "                                           tf.cast(labels_sub, tf.int32))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"
      ],
      "metadata": {
        "id": "tYcpYZWBgmxf"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ShIRo1amL_t3"
      },
      "outputs": [],
      "source": [
        "# class OptimizerVAE(object):\n",
        "#     def __init__(self, preds, labels, model, num_nodes, pos_weight, norm):\n",
        "#         preds_sub = preds\n",
        "#         labels_sub = labels\n",
        "\n",
        "#         self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "#         self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
        "\n",
        "#         # Latent loss\n",
        "#         self.log_lik = self.cost\n",
        "#         self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n",
        "#                                                                    tf.square(tf.exp(model.z_log_std)), 1))\n",
        "#         self.cost -= self.kl\n",
        "\n",
        "#         self.opt_op = self.optimizer.minimize(self.cost)\n",
        "#         self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "#         self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "#                                            tf.cast(labels_sub, tf.int32))\n",
        "#         self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "aXlIP2yNZ7hY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings\n",
        "hyper parameters"
      ],
      "metadata": {
        "id": "FexCj7amebmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "KO7kRq_9Lm-_"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Train on CPU (hide GPU) due to memory constraints\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "%cd /content/gae/gae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "mvMX8Zoabw3H"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "\n",
        "learning_rate= 0.01\n",
        "epochs= 200\n",
        "hidden1= 32\n",
        "hidden2= 16\n",
        "weight_decay= 0\n",
        "dropout= 0\n",
        "\n",
        "\n",
        "# model_str = model\n",
        "dataset_str = 'cora'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data "
      ],
      "metadata": {
        "id": "c-vkeh4iefx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "6fKASODfbPaI"
      },
      "outputs": [],
      "source": [
        "# Load data \n",
        "adj, features = load_data(dataset_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a84Cbz1vhJwk"
      },
      "source": [
        "Our own data instead of above run\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "yAGhnjXurh4S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKS81wsIjnZU",
        "outputId": "c6f6f0a4-27de-42f7-a0c6-07dba4538aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "-WgOpNUsjnim"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Content_Top1-BERT.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "3F5lER9VqH1O"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta)\n",
        "node_names = tmp.columns\n",
        "nodeslist = tmp.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "XHVC01-TjnrQ"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta).to_numpy()\n",
        "feats = tmp.transpose()\n",
        "features = sp.lil_matrix(feats)\n",
        "tmp=pd.DataFrame.from_dict(objecta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "En452TQ3mT_H"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Indexes_Top1-byTRM-Dic.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "evZeURKGkY71"
      },
      "outputs": [],
      "source": [
        "edjs=[]\n",
        "for idx, targets in objecta.items():\n",
        "  if idx in nodeslist:\n",
        "    target_str = targets.split(',')\n",
        "    for j in target_str:\n",
        "      if int(j) in nodeslist:\n",
        "        edjs.append((idx, int(j)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "5mSGObhxkZHC"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph()\n",
        "G.add_edges_from(edjs)\n",
        "degrees = [node for (node, val) in G.degree() if val>1]\n",
        "A = nx.adjacency_matrix(G, nodelist=degrees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "lAu4CJXNs2DK"
      },
      "outputs": [],
      "source": [
        "feats = tmp.loc[:, degrees].transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "q_7fpGkSu64B"
      },
      "outputs": [],
      "source": [
        "features = sp.lil_matrix(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "l0SjN0nRhMre"
      },
      "outputs": [],
      "source": [
        "adj=A"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TermsGraph_Top1.data', 'rb') as f:\n",
        "  graph_cat = pkl.load(f, encoding='latin1')\n",
        "\n",
        "# objecta.TermRelationTypeId.value_counts()\n",
        "# objecta.title.value_counts()\n",
        "# objecta.dtypes"
      ],
      "metadata": {
        "id": "e8FZ0ZLOzSVx"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store original adjacency matrix (without diagonal entries) for later\n",
        "\n",
        "train_test_val split"
      ],
      "metadata": {
        "id": "Yo3kcZHDe0A5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vOLk0K_PbqUy"
      },
      "outputs": [],
      "source": [
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "#train_test_val split\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some preprocessing"
      ],
      "metadata": {
        "id": "Abq6PpoFe46m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "QugchzLycEZm"
      },
      "outputs": [],
      "source": [
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-b_l7fZodN5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce76554b-5fe4-483c-f199-4142b298bc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define placeholders"
      ],
      "metadata": {
        "id": "FyUHfYHue8OO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "d-hrR_zycoeh"
      },
      "outputs": [],
      "source": [
        "# Define placeholders\n",
        "placeholders = {\n",
        "    'features': tf.sparse_placeholder(tf.float32),\n",
        "    'adj': tf.sparse_placeholder(tf.float32),\n",
        "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
        "    'dropout': tf.placeholder_with_default(0., shape=())\n",
        "}\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = sparse_to_tuple(features.tocoo())\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "JRg6Fbe-e_50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eAjx-RaEcytI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea351df-e9ca-421b-d293-f84bba26ed5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
        "\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "aFJYyhCDfDn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "0g-EgrcSdVDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cf7aa4-f7c9-47fa-e271-395e1137bc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "targets is deprecated, use labels instead\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "opt = OptimizerAE(preds=model.reconstructions,\n",
        "                          labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
        "                                                                      validate_indices=False), [-1]),\n",
        "                          pos_weight=pos_weight,\n",
        "                          norm=norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize session"
      ],
      "metadata": {
        "id": "UytevRDJfF0U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "TJ0NPP0moyQp"
      },
      "outputs": [],
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "cost_val = []\n",
        "acc_val = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "gFa4oL16pEjc"
      },
      "outputs": [],
      "source": [
        "def get_roc_score(edges_pos, edges_neg, emb=None):\n",
        "    if emb is None:\n",
        "        feed_dict.update({placeholders['dropout']: 0})\n",
        "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "eO7IVCBlpHK4"
      },
      "outputs": [],
      "source": [
        "cost_val = []\n",
        "acc_val = []\n",
        "val_roc_score = []\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "y3zzE68afLr6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTcXDRicpIhK",
        "outputId": "7b5827ea-f5e5-4d40-d2eb-cbf04cb47a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 train_loss= 0.79123 train_acc= 0.00221 val_roc= 0.91966 val_ap= 0.93633 time= 0.55907\n",
            "Epoch: 0002 train_loss= 0.73423 train_acc= 0.00213 val_roc= 0.91704 val_ap= 0.93466 time= 0.45862\n",
            "Epoch: 0003 train_loss= 0.68588 train_acc= 0.00213 val_roc= 0.91949 val_ap= 0.93702 time= 0.46730\n",
            "Epoch: 0004 train_loss= 0.72737 train_acc= 0.00213 val_roc= 0.92130 val_ap= 0.93895 time= 0.46260\n",
            "Epoch: 0005 train_loss= 0.68858 train_acc= 0.00213 val_roc= 0.92423 val_ap= 0.94195 time= 0.45457\n",
            "Epoch: 0006 train_loss= 0.68557 train_acc= 0.00213 val_roc= 0.92701 val_ap= 0.94476 time= 0.45019\n",
            "Epoch: 0007 train_loss= 0.69764 train_acc= 0.00213 val_roc= 0.92802 val_ap= 0.94613 time= 0.46180\n",
            "Epoch: 0008 train_loss= 0.69732 train_acc= 0.00213 val_roc= 0.92763 val_ap= 0.94613 time= 0.80624\n",
            "Epoch: 0009 train_loss= 0.68618 train_acc= 0.00213 val_roc= 0.92775 val_ap= 0.94638 time= 0.46393\n",
            "Epoch: 0010 train_loss= 0.67580 train_acc= 0.00213 val_roc= 0.92765 val_ap= 0.94613 time= 0.76112\n",
            "Epoch: 0011 train_loss= 0.67805 train_acc= 0.00213 val_roc= 0.92906 val_ap= 0.94687 time= 0.77998\n",
            "Epoch: 0012 train_loss= 0.68287 train_acc= 0.00213 val_roc= 0.93276 val_ap= 0.94931 time= 0.46019\n",
            "Epoch: 0013 train_loss= 0.67588 train_acc= 0.00213 val_roc= 0.93829 val_ap= 0.95289 time= 0.47540\n",
            "Epoch: 0014 train_loss= 0.66605 train_acc= 0.00214 val_roc= 0.94531 val_ap= 0.95683 time= 0.44833\n",
            "Epoch: 0015 train_loss= 0.66210 train_acc= 0.00238 val_roc= 0.94933 val_ap= 0.95895 time= 0.45717\n",
            "Epoch: 0016 train_loss= 0.66088 train_acc= 0.00288 val_roc= 0.95153 val_ap= 0.95962 time= 0.44606\n",
            "Epoch: 0017 train_loss= 0.65720 train_acc= 0.00346 val_roc= 0.95400 val_ap= 0.95985 time= 0.46796\n",
            "Epoch: 0018 train_loss= 0.65125 train_acc= 0.00445 val_roc= 0.95551 val_ap= 0.96000 time= 0.46015\n",
            "Epoch: 0019 train_loss= 0.64612 train_acc= 0.00680 val_roc= 0.95648 val_ap= 0.96120 time= 0.47565\n",
            "Epoch: 0020 train_loss= 0.63926 train_acc= 0.01418 val_roc= 0.95488 val_ap= 0.96061 time= 0.46853\n",
            "Epoch: 0021 train_loss= 0.63048 train_acc= 0.03104 val_roc= 0.94695 val_ap= 0.95526 time= 0.44595\n",
            "Epoch: 0022 train_loss= 0.62182 train_acc= 0.05647 val_roc= 0.93533 val_ap= 0.94696 time= 0.46967\n",
            "Epoch: 0023 train_loss= 0.61388 train_acc= 0.08674 val_roc= 0.92483 val_ap= 0.93893 time= 0.49343\n",
            "Epoch: 0024 train_loss= 0.60616 train_acc= 0.12534 val_roc= 0.91464 val_ap= 0.93098 time= 0.50577\n",
            "Epoch: 0025 train_loss= 0.59861 train_acc= 0.17053 val_roc= 0.90553 val_ap= 0.92235 time= 0.47664\n",
            "Epoch: 0026 train_loss= 0.59175 train_acc= 0.21568 val_roc= 0.89615 val_ap= 0.91254 time= 0.44968\n",
            "Epoch: 0027 train_loss= 0.58546 train_acc= 0.25425 val_roc= 0.88556 val_ap= 0.90145 time= 0.44271\n",
            "Epoch: 0028 train_loss= 0.57897 train_acc= 0.28357 val_roc= 0.86855 val_ap= 0.88709 time= 0.46430\n",
            "Epoch: 0029 train_loss= 0.57306 train_acc= 0.30582 val_roc= 0.84602 val_ap= 0.87235 time= 0.46440\n",
            "Epoch: 0030 train_loss= 0.56864 train_acc= 0.32520 val_roc= 0.82919 val_ap= 0.86194 time= 0.48202\n",
            "Epoch: 0031 train_loss= 0.56509 train_acc= 0.34384 val_roc= 0.82047 val_ap= 0.85690 time= 0.45270\n",
            "Epoch: 0032 train_loss= 0.56148 train_acc= 0.36246 val_roc= 0.81876 val_ap= 0.85608 time= 0.44268\n",
            "Epoch: 0033 train_loss= 0.55752 train_acc= 0.37904 val_roc= 0.82184 val_ap= 0.85860 time= 0.45814\n",
            "Epoch: 0034 train_loss= 0.55294 train_acc= 0.39187 val_roc= 0.82815 val_ap= 0.86339 time= 0.45695\n",
            "Epoch: 0035 train_loss= 0.54836 train_acc= 0.39959 val_roc= 0.83242 val_ap= 0.86707 time= 0.45093\n",
            "Epoch: 0036 train_loss= 0.54489 train_acc= 0.40677 val_roc= 0.82986 val_ap= 0.86683 time= 0.45817\n",
            "Epoch: 0037 train_loss= 0.54208 train_acc= 0.41696 val_roc= 0.82394 val_ap= 0.86296 time= 0.46345\n",
            "Epoch: 0038 train_loss= 0.53919 train_acc= 0.43092 val_roc= 0.81812 val_ap= 0.85883 time= 0.46380\n",
            "Epoch: 0039 train_loss= 0.53689 train_acc= 0.44401 val_roc= 0.81719 val_ap= 0.85774 time= 0.46483\n",
            "Epoch: 0040 train_loss= 0.53542 train_acc= 0.44891 val_roc= 0.82517 val_ap= 0.86273 time= 0.44906\n",
            "Epoch: 0041 train_loss= 0.53408 train_acc= 0.44353 val_roc= 0.83684 val_ap= 0.87179 time= 0.43210\n",
            "Epoch: 0042 train_loss= 0.53305 train_acc= 0.43321 val_roc= 0.84259 val_ap= 0.87682 time= 0.45520\n",
            "Epoch: 0043 train_loss= 0.53218 train_acc= 0.42771 val_roc= 0.83943 val_ap= 0.87481 time= 0.44429\n",
            "Epoch: 0044 train_loss= 0.53079 train_acc= 0.43221 val_roc= 0.83356 val_ap= 0.87111 time= 0.47481\n",
            "Epoch: 0045 train_loss= 0.52945 train_acc= 0.44282 val_roc= 0.83034 val_ap= 0.86882 time= 0.46301\n",
            "Epoch: 0046 train_loss= 0.52856 train_acc= 0.45131 val_roc= 0.83538 val_ap= 0.87217 time= 0.46111\n",
            "Epoch: 0047 train_loss= 0.52724 train_acc= 0.45133 val_roc= 0.84555 val_ap= 0.88050 time= 0.46286\n",
            "Epoch: 0048 train_loss= 0.52580 train_acc= 0.44468 val_roc= 0.85117 val_ap= 0.88461 time= 0.44733\n",
            "Epoch: 0049 train_loss= 0.52480 train_acc= 0.43933 val_roc= 0.85117 val_ap= 0.88530 time= 0.45643\n",
            "Epoch: 0050 train_loss= 0.52347 train_acc= 0.44133 val_roc= 0.84567 val_ap= 0.88151 time= 0.47060\n",
            "Epoch: 0051 train_loss= 0.52204 train_acc= 0.44924 val_roc= 0.84142 val_ap= 0.87826 time= 0.46573\n",
            "Epoch: 0052 train_loss= 0.52087 train_acc= 0.45675 val_roc= 0.84197 val_ap= 0.87811 time= 0.48357\n",
            "Epoch: 0053 train_loss= 0.51947 train_acc= 0.45893 val_roc= 0.84699 val_ap= 0.88208 time= 0.77839\n",
            "Epoch: 0054 train_loss= 0.51801 train_acc= 0.45623 val_roc= 0.85071 val_ap= 0.88522 time= 0.45037\n",
            "Epoch: 0055 train_loss= 0.51680 train_acc= 0.45336 val_roc= 0.85001 val_ap= 0.88508 time= 0.46419\n",
            "Epoch: 0056 train_loss= 0.51535 train_acc= 0.45532 val_roc= 0.84578 val_ap= 0.88178 time= 0.44550\n",
            "Epoch: 0057 train_loss= 0.51383 train_acc= 0.46132 val_roc= 0.84246 val_ap= 0.87939 time= 0.44658\n",
            "Epoch: 0058 train_loss= 0.51257 train_acc= 0.46623 val_roc= 0.84393 val_ap= 0.88096 time= 0.46524\n",
            "Epoch: 0059 train_loss= 0.51118 train_acc= 0.46666 val_roc= 0.84849 val_ap= 0.88487 time= 0.46346\n",
            "Epoch: 0060 train_loss= 0.50984 train_acc= 0.46384 val_roc= 0.85244 val_ap= 0.88792 time= 0.45223\n",
            "Epoch: 0061 train_loss= 0.50873 train_acc= 0.46254 val_roc= 0.85133 val_ap= 0.88681 time= 0.46614\n",
            "Epoch: 0062 train_loss= 0.50755 train_acc= 0.46538 val_roc= 0.84791 val_ap= 0.88469 time= 0.46977\n",
            "Epoch: 0063 train_loss= 0.50650 train_acc= 0.47006 val_roc= 0.84694 val_ap= 0.88446 time= 0.46614\n",
            "Epoch: 0064 train_loss= 0.50551 train_acc= 0.47250 val_roc= 0.84962 val_ap= 0.88697 time= 0.45576\n",
            "Epoch: 0065 train_loss= 0.50446 train_acc= 0.47169 val_roc= 0.85316 val_ap= 0.88981 time= 0.44371\n",
            "Epoch: 0066 train_loss= 0.50349 train_acc= 0.47094 val_roc= 0.85350 val_ap= 0.89029 time= 0.45673\n",
            "Epoch: 0067 train_loss= 0.50247 train_acc= 0.47371 val_roc= 0.85135 val_ap= 0.88874 time= 0.45182\n",
            "Epoch: 0068 train_loss= 0.50149 train_acc= 0.47813 val_roc= 0.85092 val_ap= 0.88868 time= 0.45917\n",
            "Epoch: 0069 train_loss= 0.50059 train_acc= 0.48025 val_roc= 0.85369 val_ap= 0.89113 time= 0.46194\n",
            "Epoch: 0070 train_loss= 0.49968 train_acc= 0.47944 val_roc= 0.85630 val_ap= 0.89313 time= 0.45277\n",
            "Epoch: 0071 train_loss= 0.49888 train_acc= 0.47904 val_roc= 0.85656 val_ap= 0.89343 time= 0.45008\n",
            "Epoch: 0072 train_loss= 0.49805 train_acc= 0.48210 val_roc= 0.85565 val_ap= 0.89274 time= 0.58246\n",
            "Epoch: 0073 train_loss= 0.49727 train_acc= 0.48636 val_roc= 0.85630 val_ap= 0.89325 time= 0.68614\n",
            "Epoch: 0074 train_loss= 0.49647 train_acc= 0.48755 val_roc= 0.85850 val_ap= 0.89537 time= 0.75483\n",
            "Epoch: 0075 train_loss= 0.49567 train_acc= 0.48626 val_roc= 0.85914 val_ap= 0.89636 time= 0.72499\n",
            "Epoch: 0076 train_loss= 0.49492 train_acc= 0.48702 val_roc= 0.85753 val_ap= 0.89512 time= 0.67969\n",
            "Epoch: 0077 train_loss= 0.49416 train_acc= 0.49066 val_roc= 0.85739 val_ap= 0.89522 time= 0.69948\n",
            "Epoch: 0078 train_loss= 0.49346 train_acc= 0.49297 val_roc= 0.85877 val_ap= 0.89644 time= 0.69850\n",
            "Epoch: 0079 train_loss= 0.49275 train_acc= 0.49237 val_roc= 0.85977 val_ap= 0.89764 time= 0.44950\n",
            "Epoch: 0080 train_loss= 0.49207 train_acc= 0.49254 val_roc= 0.85806 val_ap= 0.89656 time= 0.47140\n",
            "Epoch: 0081 train_loss= 0.49138 train_acc= 0.49462 val_roc= 0.85822 val_ap= 0.89702 time= 0.45864\n",
            "Epoch: 0082 train_loss= 0.49070 train_acc= 0.49533 val_roc= 0.86078 val_ap= 0.89951 time= 0.46331\n",
            "Epoch: 0083 train_loss= 0.48998 train_acc= 0.49395 val_roc= 0.86111 val_ap= 0.89994 time= 0.43696\n",
            "Epoch: 0084 train_loss= 0.48927 train_acc= 0.49443 val_roc= 0.85958 val_ap= 0.89877 time= 0.46711\n",
            "Epoch: 0085 train_loss= 0.48855 train_acc= 0.49680 val_roc= 0.86083 val_ap= 0.90013 time= 0.45356\n",
            "Epoch: 0086 train_loss= 0.48781 train_acc= 0.49645 val_roc= 0.86210 val_ap= 0.90114 time= 0.45950\n",
            "Epoch: 0087 train_loss= 0.48709 train_acc= 0.49572 val_roc= 0.86085 val_ap= 0.90022 time= 0.45335\n",
            "Epoch: 0088 train_loss= 0.48638 train_acc= 0.49774 val_roc= 0.86183 val_ap= 0.90121 time= 0.45615\n",
            "Epoch: 0089 train_loss= 0.48566 train_acc= 0.49782 val_roc= 0.86354 val_ap= 0.90281 time= 0.45620\n",
            "Epoch: 0090 train_loss= 0.48491 train_acc= 0.49753 val_roc= 0.86134 val_ap= 0.90141 time= 0.46287\n",
            "Epoch: 0091 train_loss= 0.48412 train_acc= 0.49962 val_roc= 0.86217 val_ap= 0.90252 time= 0.45641\n",
            "Epoch: 0092 train_loss= 0.48331 train_acc= 0.49931 val_roc= 0.86287 val_ap= 0.90341 time= 0.45582\n",
            "Epoch: 0093 train_loss= 0.48249 train_acc= 0.49888 val_roc= 0.86042 val_ap= 0.90174 time= 0.46148\n",
            "Epoch: 0094 train_loss= 0.48163 train_acc= 0.50062 val_roc= 0.86185 val_ap= 0.90318 time= 0.45147\n",
            "Epoch: 0095 train_loss= 0.48072 train_acc= 0.50004 val_roc= 0.86169 val_ap= 0.90349 time= 0.47057\n",
            "Epoch: 0096 train_loss= 0.47979 train_acc= 0.50079 val_roc= 0.86025 val_ap= 0.90270 time= 0.46266\n",
            "Epoch: 0097 train_loss= 0.47884 train_acc= 0.50247 val_roc= 0.86155 val_ap= 0.90372 time= 0.46100\n",
            "Epoch: 0098 train_loss= 0.47790 train_acc= 0.50202 val_roc= 0.86060 val_ap= 0.90296 time= 0.43990\n",
            "Epoch: 0099 train_loss= 0.47695 train_acc= 0.50340 val_roc= 0.86104 val_ap= 0.90325 time= 0.44181\n",
            "Epoch: 0100 train_loss= 0.47602 train_acc= 0.50384 val_roc= 0.86185 val_ap= 0.90356 time= 0.45197\n",
            "Epoch: 0101 train_loss= 0.47514 train_acc= 0.50397 val_roc= 0.86014 val_ap= 0.90155 time= 0.43445\n",
            "Epoch: 0102 train_loss= 0.47430 train_acc= 0.50577 val_roc= 0.86157 val_ap= 0.90200 time= 0.46053\n",
            "Epoch: 0103 train_loss= 0.47351 train_acc= 0.50532 val_roc= 0.86048 val_ap= 0.90060 time= 0.43472\n",
            "Epoch: 0104 train_loss= 0.47281 train_acc= 0.50674 val_roc= 0.86088 val_ap= 0.90077 time= 0.45981\n",
            "Epoch: 0105 train_loss= 0.47220 train_acc= 0.50697 val_roc= 0.86102 val_ap= 0.90030 time= 0.44741\n",
            "Epoch: 0106 train_loss= 0.47170 train_acc= 0.50687 val_roc= 0.85905 val_ap= 0.89768 time= 0.45589\n",
            "Epoch: 0107 train_loss= 0.47129 train_acc= 0.50800 val_roc= 0.85988 val_ap= 0.89731 time= 0.44737\n",
            "Epoch: 0108 train_loss= 0.47097 train_acc= 0.50705 val_roc= 0.85753 val_ap= 0.89499 time= 0.44945\n",
            "Epoch: 0109 train_loss= 0.47071 train_acc= 0.50873 val_roc= 0.85986 val_ap= 0.89685 time= 0.46761\n",
            "Epoch: 0110 train_loss= 0.47046 train_acc= 0.50675 val_roc= 0.85593 val_ap= 0.89316 time= 0.45086\n",
            "Epoch: 0111 train_loss= 0.47022 train_acc= 0.51023 val_roc= 0.86148 val_ap= 0.89744 time= 0.44438\n",
            "Epoch: 0112 train_loss= 0.47000 train_acc= 0.50534 val_roc= 0.85371 val_ap= 0.89037 time= 0.44160\n",
            "Epoch: 0113 train_loss= 0.46978 train_acc= 0.51212 val_roc= 0.86344 val_ap= 0.89885 time= 0.46957\n",
            "Epoch: 0114 train_loss= 0.46944 train_acc= 0.50416 val_roc= 0.85450 val_ap= 0.89119 time= 0.44762\n",
            "Epoch: 0115 train_loss= 0.46892 train_acc= 0.51224 val_roc= 0.86152 val_ap= 0.89738 time= 0.45129\n",
            "Epoch: 0116 train_loss= 0.46830 train_acc= 0.50694 val_roc= 0.85935 val_ap= 0.89545 time= 0.46116\n",
            "Epoch: 0117 train_loss= 0.46778 train_acc= 0.50929 val_roc= 0.85739 val_ap= 0.89446 time= 0.48961\n",
            "Epoch: 0118 train_loss= 0.46748 train_acc= 0.51128 val_roc= 0.86395 val_ap= 0.90088 time= 0.51315\n",
            "Epoch: 0119 train_loss= 0.46729 train_acc= 0.50598 val_roc= 0.85524 val_ap= 0.89366 time= 0.45483\n",
            "Epoch: 0120 train_loss= 0.46700 train_acc= 0.51318 val_roc= 0.86367 val_ap= 0.90127 time= 0.45864\n",
            "Epoch: 0121 train_loss= 0.46659 train_acc= 0.50688 val_roc= 0.85868 val_ap= 0.89782 time= 0.45013\n",
            "Epoch: 0122 train_loss= 0.46611 train_acc= 0.51134 val_roc= 0.85921 val_ap= 0.89873 time= 0.46020\n",
            "Epoch: 0123 train_loss= 0.46583 train_acc= 0.51139 val_roc= 0.86298 val_ap= 0.90177 time= 0.43965\n",
            "Epoch: 0124 train_loss= 0.46570 train_acc= 0.50803 val_roc= 0.85579 val_ap= 0.89659 time= 0.45555\n",
            "Epoch: 0125 train_loss= 0.46548 train_acc= 0.51336 val_roc= 0.86208 val_ap= 0.90141 time= 0.45412\n",
            "Epoch: 0126 train_loss= 0.46510 train_acc= 0.50920 val_roc= 0.85868 val_ap= 0.89914 time= 0.45013\n",
            "Epoch: 0127 train_loss= 0.46473 train_acc= 0.51181 val_roc= 0.85699 val_ap= 0.89790 time= 0.44691\n",
            "Epoch: 0128 train_loss= 0.46449 train_acc= 0.51284 val_roc= 0.86152 val_ap= 0.90103 time= 0.47175\n",
            "Epoch: 0129 train_loss= 0.46430 train_acc= 0.50990 val_roc= 0.85466 val_ap= 0.89581 time= 0.46040\n",
            "Epoch: 0130 train_loss= 0.46405 train_acc= 0.51443 val_roc= 0.86085 val_ap= 0.90055 time= 0.46717\n",
            "Epoch: 0131 train_loss= 0.46373 train_acc= 0.51073 val_roc= 0.85535 val_ap= 0.89643 time= 0.46029\n",
            "Epoch: 0132 train_loss= 0.46337 train_acc= 0.51435 val_roc= 0.85676 val_ap= 0.89723 time= 0.46306\n",
            "Epoch: 0133 train_loss= 0.46305 train_acc= 0.51346 val_roc= 0.85831 val_ap= 0.89829 time= 0.45776\n",
            "Epoch: 0134 train_loss= 0.46279 train_acc= 0.51276 val_roc= 0.85353 val_ap= 0.89475 time= 0.46510\n",
            "Epoch: 0135 train_loss= 0.46260 train_acc= 0.51576 val_roc= 0.85998 val_ap= 0.89904 time= 0.46656\n",
            "Epoch: 0136 train_loss= 0.46241 train_acc= 0.51183 val_roc= 0.85159 val_ap= 0.89334 time= 0.47018\n",
            "Epoch: 0137 train_loss= 0.46220 train_acc= 0.51735 val_roc= 0.85995 val_ap= 0.89901 time= 0.43712\n",
            "Epoch: 0138 train_loss= 0.46193 train_acc= 0.51217 val_roc= 0.85196 val_ap= 0.89373 time= 0.45988\n",
            "Epoch: 0139 train_loss= 0.46160 train_acc= 0.51740 val_roc= 0.85810 val_ap= 0.89760 time= 0.45641\n",
            "Epoch: 0140 train_loss= 0.46125 train_acc= 0.51384 val_roc= 0.85478 val_ap= 0.89544 time= 0.47310\n",
            "Epoch: 0141 train_loss= 0.46091 train_acc= 0.51637 val_roc= 0.85459 val_ap= 0.89539 time= 0.45973\n",
            "Epoch: 0142 train_loss= 0.46064 train_acc= 0.51651 val_roc= 0.85702 val_ap= 0.89709 time= 0.46178\n",
            "Epoch: 0143 train_loss= 0.46043 train_acc= 0.51493 val_roc= 0.85193 val_ap= 0.89377 time= 0.44253\n",
            "Epoch: 0144 train_loss= 0.46020 train_acc= 0.51821 val_roc= 0.85783 val_ap= 0.89778 time= 0.45808\n",
            "Epoch: 0145 train_loss= 0.45996 train_acc= 0.51464 val_roc= 0.85142 val_ap= 0.89356 time= 0.45004\n",
            "Epoch: 0146 train_loss= 0.45965 train_acc= 0.51868 val_roc= 0.85616 val_ap= 0.89688 time= 0.43349\n",
            "Epoch: 0147 train_loss= 0.45930 train_acc= 0.51606 val_roc= 0.85323 val_ap= 0.89512 time= 0.44987\n",
            "Epoch: 0148 train_loss= 0.45896 train_acc= 0.51781 val_roc= 0.85288 val_ap= 0.89498 time= 0.44956\n",
            "Epoch: 0149 train_loss= 0.45867 train_acc= 0.51829 val_roc= 0.85605 val_ap= 0.89768 time= 0.45444\n",
            "Epoch: 0150 train_loss= 0.45842 train_acc= 0.51692 val_roc= 0.84997 val_ap= 0.89329 time= 0.44822\n",
            "Epoch: 0151 train_loss= 0.45819 train_acc= 0.52036 val_roc= 0.85764 val_ap= 0.89895 time= 0.46340\n",
            "Epoch: 0152 train_loss= 0.45797 train_acc= 0.51644 val_roc= 0.84870 val_ap= 0.89281 time= 0.45545\n",
            "Epoch: 0153 train_loss= 0.45768 train_acc= 0.52173 val_roc= 0.85750 val_ap= 0.89923 time= 0.45901\n",
            "Epoch: 0154 train_loss= 0.45736 train_acc= 0.51736 val_roc= 0.84888 val_ap= 0.89304 time= 0.43902\n",
            "Epoch: 0155 train_loss= 0.45693 train_acc= 0.52213 val_roc= 0.85401 val_ap= 0.89692 time= 0.44940\n",
            "Epoch: 0156 train_loss= 0.45650 train_acc= 0.52017 val_roc= 0.85228 val_ap= 0.89577 time= 0.47211\n",
            "Epoch: 0157 train_loss= 0.45613 train_acc= 0.52148 val_roc= 0.84941 val_ap= 0.89345 time= 0.45138\n",
            "Epoch: 0158 train_loss= 0.45584 train_acc= 0.52330 val_roc= 0.85512 val_ap= 0.89778 time= 0.46617\n",
            "Epoch: 0159 train_loss= 0.45561 train_acc= 0.52106 val_roc= 0.84650 val_ap= 0.89160 time= 0.50093\n",
            "Epoch: 0160 train_loss= 0.45535 train_acc= 0.52569 val_roc= 0.85561 val_ap= 0.89776 time= 0.50995\n",
            "Epoch: 0161 train_loss= 0.45505 train_acc= 0.52180 val_roc= 0.84585 val_ap= 0.89114 time= 0.44658\n",
            "Epoch: 0162 train_loss= 0.45466 train_acc= 0.52718 val_roc= 0.85270 val_ap= 0.89583 time= 0.44584\n",
            "Epoch: 0163 train_loss= 0.45419 train_acc= 0.52454 val_roc= 0.84860 val_ap= 0.89262 time= 0.51760\n",
            "Epoch: 0164 train_loss= 0.45378 train_acc= 0.52720 val_roc= 0.84715 val_ap= 0.89138 time= 0.50608\n",
            "Epoch: 0165 train_loss= 0.45347 train_acc= 0.52833 val_roc= 0.85147 val_ap= 0.89430 time= 0.46248\n",
            "Epoch: 0166 train_loss= 0.45325 train_acc= 0.52648 val_roc= 0.84289 val_ap= 0.88826 time= 0.43647\n",
            "Epoch: 0167 train_loss= 0.45307 train_acc= 0.53109 val_roc= 0.85350 val_ap= 0.89525 time= 0.45595\n",
            "Epoch: 0168 train_loss= 0.45289 train_acc= 0.52648 val_roc= 0.84088 val_ap= 0.88665 time= 0.46649\n",
            "Epoch: 0169 train_loss= 0.45259 train_acc= 0.53268 val_roc= 0.85156 val_ap= 0.89413 time= 0.45258\n",
            "Epoch: 0170 train_loss= 0.45223 train_acc= 0.52804 val_roc= 0.84202 val_ap= 0.88733 time= 0.46757\n",
            "Epoch: 0171 train_loss= 0.45182 train_acc= 0.53252 val_roc= 0.84484 val_ap= 0.88921 time= 0.44608\n",
            "Epoch: 0172 train_loss= 0.45148 train_acc= 0.53128 val_roc= 0.84611 val_ap= 0.89024 time= 0.44742\n",
            "Epoch: 0173 train_loss= 0.45129 train_acc= 0.53072 val_roc= 0.83899 val_ap= 0.88542 time= 0.46467\n",
            "Epoch: 0174 train_loss= 0.45118 train_acc= 0.53362 val_roc= 0.84823 val_ap= 0.89166 time= 0.45876\n",
            "Epoch: 0175 train_loss= 0.45108 train_acc= 0.52940 val_roc= 0.83668 val_ap= 0.88432 time= 0.46653\n",
            "Epoch: 0176 train_loss= 0.45086 train_acc= 0.53424 val_roc= 0.84604 val_ap= 0.89048 time= 0.45020\n",
            "Epoch: 0177 train_loss= 0.45058 train_acc= 0.53001 val_roc= 0.83776 val_ap= 0.88548 time= 0.44012\n",
            "Epoch: 0178 train_loss= 0.45025 train_acc= 0.53326 val_roc= 0.83964 val_ap= 0.88686 time= 0.46200\n",
            "Epoch: 0179 train_loss= 0.44998 train_acc= 0.53214 val_roc= 0.84118 val_ap= 0.88784 time= 0.45553\n",
            "Epoch: 0180 train_loss= 0.44981 train_acc= 0.53109 val_roc= 0.83485 val_ap= 0.88441 time= 0.45043\n",
            "Epoch: 0181 train_loss= 0.44968 train_acc= 0.53342 val_roc= 0.84229 val_ap= 0.88939 time= 0.45224\n",
            "Epoch: 0182 train_loss= 0.44951 train_acc= 0.52987 val_roc= 0.83335 val_ap= 0.88384 time= 0.46963\n",
            "Epoch: 0183 train_loss= 0.44925 train_acc= 0.53323 val_roc= 0.83913 val_ap= 0.88787 time= 0.49831\n",
            "Epoch: 0184 train_loss= 0.44896 train_acc= 0.53068 val_roc= 0.83531 val_ap= 0.88576 time= 0.50680\n",
            "Epoch: 0185 train_loss= 0.44869 train_acc= 0.53193 val_roc= 0.83464 val_ap= 0.88568 time= 0.46413\n",
            "Epoch: 0186 train_loss= 0.44847 train_acc= 0.53192 val_roc= 0.83753 val_ap= 0.88773 time= 0.46361\n",
            "Epoch: 0187 train_loss= 0.44829 train_acc= 0.53055 val_roc= 0.83166 val_ap= 0.88427 time= 0.45295\n",
            "Epoch: 0188 train_loss= 0.44813 train_acc= 0.53272 val_roc= 0.83885 val_ap= 0.88864 time= 0.44936\n",
            "Epoch: 0189 train_loss= 0.44800 train_acc= 0.52941 val_roc= 0.82900 val_ap= 0.88298 time= 0.46887\n",
            "Epoch: 0190 train_loss= 0.44787 train_acc= 0.53330 val_roc= 0.84026 val_ap= 0.88993 time= 0.44146\n",
            "Epoch: 0191 train_loss= 0.44776 train_acc= 0.52850 val_roc= 0.82732 val_ap= 0.88198 time= 0.46507\n",
            "Epoch: 0192 train_loss= 0.44757 train_acc= 0.53355 val_roc= 0.83922 val_ap= 0.88962 time= 0.49316\n",
            "Epoch: 0193 train_loss= 0.44732 train_acc= 0.52859 val_roc= 0.82819 val_ap= 0.88279 time= 0.48685\n",
            "Epoch: 0194 train_loss= 0.44695 train_acc= 0.53302 val_roc= 0.83397 val_ap= 0.88640 time= 0.44871\n",
            "Epoch: 0195 train_loss= 0.44660 train_acc= 0.53055 val_roc= 0.83210 val_ap= 0.88539 time= 0.45690\n",
            "Epoch: 0196 train_loss= 0.44636 train_acc= 0.53117 val_roc= 0.82829 val_ap= 0.88270 time= 0.45985\n",
            "Epoch: 0197 train_loss= 0.44623 train_acc= 0.53246 val_roc= 0.83462 val_ap= 0.88713 time= 0.45313\n",
            "Epoch: 0198 train_loss= 0.44614 train_acc= 0.52939 val_roc= 0.82535 val_ap= 0.88089 time= 0.45686\n",
            "Epoch: 0199 train_loss= 0.44598 train_acc= 0.53318 val_roc= 0.83379 val_ap= 0.88655 time= 0.46172\n",
            "Epoch: 0200 train_loss= 0.44574 train_acc= 0.52954 val_roc= 0.82602 val_ap= 0.88161 time= 0.46949\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.8045199241863906\n",
            "Test AP score: 0.8649358494730401\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: dropout})\n",
        "    # Run single weight update\n",
        "    outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
        "\n",
        "    # Compute average loss\n",
        "    avg_cost = outs[1]\n",
        "    avg_accuracy = outs[2]\n",
        "\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
        "    val_roc_score.append(roc_curr)\n",
        "\n",
        "    print(\"Epoch:\" , '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
        "          \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
        "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
        "print('Test ROC score: ' + str(roc_score))\n",
        "print('Test AP score: ' + str(ap_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :)\n"
      ],
      "metadata": {
        "id": "hE4aW2Atfh0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IWWHDUlcWtOr"
      },
      "outputs": [],
      "source": [
        "# https://www.programcreek.com/python/\n",
        "# https://book.pythontips.com/en/latest/args_and_kwargs.html\n",
        "\n",
        "# np.sum(A[65,:].toarray()[0])\n",
        "# degrees = [node for (node, val) in G.degree() if val>5]\n",
        "\n",
        "# tmp = np.random.rand(2072, 16)\n",
        "# def sigmoid(x): \n",
        "#         return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Predict on test set of edges\n",
        "# adj_tmp = np.dot(tmp, tmp.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IDCC3SowEG5P"
      },
      "outputs": [],
      "source": [
        "# def get_roc_score_a(edges_pos, edges_neg, emb=None):\n",
        "#     if emb is None:\n",
        "#         # feed_dict.update({placeholders['dropout']: 0})\n",
        "#         emb = tmp\n",
        "\n",
        "#     def sigmoid(x):\n",
        "#         return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#     # Predict on test set of edges\n",
        "#     adj_rec = np.dot(emb, emb.T)\n",
        "#     preds = []\n",
        "#     pos = []\n",
        "#     for e in edges_pos:\n",
        "#         preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "#         pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "#     preds_neg = []\n",
        "#     neg = []\n",
        "#     for e in edges_neg:\n",
        "#         preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "#         neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "#     preds_all = np.hstack([preds, preds_neg])\n",
        "#     labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "#     roc_score = roc_auc_score(labels_all, preds_all)\n",
        "#     ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "#     return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XurHgBQKDYip"
      },
      "outputs": [],
      "source": [
        "# adj_label = adj_train + sp.eye(adj_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "#     coo = X.tocoo()\n",
        "#     indices = np.mat([coo.row, coo.col]).transpose()\n",
        "#     return tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "\n",
        "# x = convert_sparse_matrix_to_sparse_tensor(adj_label)"
      ],
      "metadata": {
        "id": "tAkmm-py5ZZ5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "klulqViA_3Wq"
      },
      "outputs": [],
      "source": [
        "# correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(adj_tmp), 0.5), tf.int32),\n",
        "#                                            tf.cast(adj_label.todense(), tf.int32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Z5byLKFHEx2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4be27e-6ebe-46ab-eb97-f8a56b0a229d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5168038091715976 0.510831796570484\n"
          ]
        }
      ],
      "source": [
        "# roc_curr, ap_curr = get_roc_score_a(val_edges, val_edges_false)\n",
        "# print(roc_curr, ap_curr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "k_pjsEiLE7tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc629c3-6549-4fbd-bcde-5a6c43baeb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5497180103550295 0.5322798391910993\n"
          ]
        }
      ],
      "source": [
        "# roc_curr, ap_curr = get_roc_score_a(test_edges, test_edges_false)\n",
        "# print(roc_curr, ap_curr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E1CcRpGCX3De",
        "3kPmH5zMYj6Q",
        "1G_VlvyFZFWv",
        "GFs3RJdIZ995",
        "YgNYjfErZiEV",
        "LxOUv5YHYJ19",
        "fBL84Q2LZsiR",
        "FexCj7amebmj",
        "Yo3kcZHDe0A5",
        "Abq6PpoFe46m",
        "FyUHfYHue8OO",
        "JRg6Fbe-e_50",
        "aFJYyhCDfDn8",
        "UytevRDJfF0U",
        "y3zzE68afLr6"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}