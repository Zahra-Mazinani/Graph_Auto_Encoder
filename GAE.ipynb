{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahra-Mazinani/Graph_Auto_Encoder/blob/main/GAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "E1CcRpGCX3De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1fQJjL4LYWf",
        "outputId": "335c9bc5-0c7b-495f-f682-5f9442877765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gae' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tkipf/gae.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2DKBYKfWLjdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f582fa-61f6-40b1-dec2-35106af030be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing gae.egg-info/PKG-INFO\n",
            "writing dependency_links to gae.egg-info/dependency_links.txt\n",
            "writing requirements to gae.egg-info/requires.txt\n",
            "writing top-level names to gae.egg-info/top_level.txt\n",
            "reading manifest file 'gae.egg-info/SOURCES.txt'\n",
            "writing manifest file 'gae.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gae.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/gae-0.0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing gae-0.0.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Copying gae-0.0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "gae 0.0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/gae-0.0.1-py3.7.egg\n",
            "Processing dependencies for gae==0.0.1\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.3\n",
            "Best match: networkx 2.6.3\n",
            "Adding networkx 2.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow==2.9.2\n",
            "Best match: tensorflow 2.9.2\n",
            "Adding tensorflow 2.9.2 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing import_pb_to_tensorboard script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for h5py==3.1.0\n",
            "Best match: h5py 3.1.0\n",
            "Adding h5py 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==2.0.1\n",
            "Best match: termcolor 2.0.1\n",
            "Adding termcolor 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.49.1\n",
            "Best match: grpcio 1.49.1\n",
            "Adding grpcio 1.49.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.9.1\n",
            "Best match: tensorboard 2.9.1\n",
            "Adding tensorboard 2.9.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gast==0.4.0\n",
            "Best match: gast 0.4.0\n",
            "Adding gast 0.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for keras==2.9.0\n",
            "Best match: keras 2.9.0\n",
            "Adding keras 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wrapt==1.14.1\n",
            "Best match: wrapt 1.14.1\n",
            "Adding wrapt 1.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-estimator==2.9.0\n",
            "Best match: tensorflow-estimator 2.9.0\n",
            "Adding tensorflow-estimator 2.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for flatbuffers==1.12\n",
            "Best match: flatbuffers 1.12\n",
            "Adding flatbuffers 1.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for libclang==14.0.6\n",
            "Best match: libclang 14.0.6\n",
            "Adding libclang 14.0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorflow-io-gcs-filesystem==0.27.0\n",
            "Best match: tensorflow-io-gcs-filesystem 0.27.0\n",
            "Adding tensorflow-io-gcs-filesystem 0.27.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opt-einsum==3.3.0\n",
            "Best match: opt-einsum 3.3.0\n",
            "Adding opt-einsum 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cached-property==1.5.2\n",
            "Best match: cached-property 1.5.2\n",
            "Adding cached-property 1.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.9.24\n",
            "Best match: certifi 2022.9.24\n",
            "Adding certifi 2022.9.24 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.13.0\n",
            "Best match: importlib-metadata 4.13.0\n",
            "Adding importlib-metadata 4.13.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.1\n",
            "Best match: oauthlib 3.2.1\n",
            "Adding oauthlib 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.9.0\n",
            "Best match: zipp 3.9.0\n",
            "Adding zipp 3.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for gae==0.0.1\n"
          ]
        }
      ],
      "source": [
        "# In cell ro bardar. Lazem nadari\n",
        "\n",
        "!python /content/gae/setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "egtdHtZEYBD7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializations"
      ],
      "metadata": {
        "id": "3kPmH5zMYj6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k_tGZM3fM11T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
        "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010)\n",
        "    initialization.\n",
        "    \"\"\"\n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n",
        "                                maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input data"
      ],
      "metadata": {
        "id": "1G_VlvyFZFWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "kh0JUMJ3fzWd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index"
      ],
      "metadata": {
        "id": "woM31ouTf2a1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"data/ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "metadata": {
        "id": "DT6QoeI5ZD0j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "GFs3RJdIZ995"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8JFBub93cjhG"
      },
      "outputs": [],
      "source": [
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CZeEkbLCpYqt"
      },
      "outputs": [],
      "source": [
        "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
        "    # construct feed dictionary\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
        "    feed_dict.update({placeholders['adj_orig']: adj})\n",
        "    return feed_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)"
      ],
      "metadata": {
        "id": "XD6OoK30c-Br"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IxSUBYYdcaQg"
      },
      "outputs": [],
      "source": [
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Layers"
      ],
      "metadata": {
        "id": "YgNYjfErZiEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# global unique layer ID dictionary for layer name assignment\n",
        "_LAYER_UIDS = {}"
      ],
      "metadata": {
        "id": "qLV8gOgGf8zY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layer_uid(layer_name=''):\n",
        "    \"\"\"Helper function, assigns unique layer IDs\n",
        "    \"\"\"\n",
        "    if layer_name not in _LAYER_UIDS:\n",
        "        _LAYER_UIDS[layer_name] = 1\n",
        "        return 1\n",
        "    else:\n",
        "        _LAYER_UIDS[layer_name] += 1\n",
        "        return _LAYER_UIDS[layer_name]"
      ],
      "metadata": {
        "id": "f8FMscFIf-uF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
        "    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n",
        "    \"\"\"\n",
        "    noise_shape = [num_nonzero_elems]\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1./keep_prob)"
      ],
      "metadata": {
        "id": "6LVe-UZigCrJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(object):\n",
        "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
        "\n",
        "    # Properties\n",
        "        name: String, defines the variable scope of the layer.\n",
        "\n",
        "    # Methods\n",
        "        _call(inputs): Defines computation graph of layer\n",
        "            (i.e. takes input, returns output)\n",
        "        __call__(inputs): Wrapper for _call()\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            layer = self.__class__.__name__.lower()\n",
        "            name = layer + '_' + str(get_layer_uid(layer))\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "        self.issparse = False\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            outputs = self._call(inputs)\n",
        "            return outputs"
      ],
      "metadata": {
        "id": "Q_QqoKTygNms"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(Layer):\n",
        "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolution, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = tf.nn.dropout(x, 1-self.dropout)\n",
        "        x = tf.matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "-hqbqd1ygQSX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolutionSparse(Layer):\n",
        "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n",
        "        super(GraphConvolutionSparse, self).__init__(**kwargs)\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = True\n",
        "        self.features_nonzero = features_nonzero\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
        "        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n",
        "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "        outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "JmZoQ9-OgVG3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wtHW27IUMvic"
      },
      "outputs": [],
      "source": [
        "class InnerProductDecoder(Layer):\n",
        "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
        "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
        "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
        "        x = tf.transpose(inputs)\n",
        "        x = tf.matmul(inputs, x)\n",
        "        x = tf.reshape(x, [-1])\n",
        "        outputs = self.act(x)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "LxOUv5YHYJ19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DKID7cetnyDO"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            name = self.__class__.__name__.lower()\n",
        "        self.name = name\n",
        "\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "\n",
        "        self.vars = {}\n",
        "\n",
        "    def _build(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\" Wrapper for _build() \"\"\"\n",
        "        with tf.variable_scope(self.name):\n",
        "            self._build()\n",
        "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "        self.vars = {var.name: var for var in variables}\n",
        "\n",
        "    def fit(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NUpRwgUan07z"
      },
      "outputs": [],
      "source": [
        "class GCNModelAE(Model):\n",
        "    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n",
        "        super(GCNModelAE, self).__init__(**kwargs)\n",
        "\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = num_features\n",
        "        self.features_nonzero = features_nonzero\n",
        "        self.adj = placeholders['adj']\n",
        "        self.dropout = placeholders['dropout']\n",
        "        self.build()\n",
        "\n",
        "    def _build(self):\n",
        "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
        "                                              output_dim=hidden1,\n",
        "                                              adj=self.adj,\n",
        "                                              features_nonzero=self.features_nonzero,\n",
        "                                              act=tf.nn.relu,\n",
        "                                              dropout=self.dropout,\n",
        "                                              logging=self.logging)(self.inputs)\n",
        "\n",
        "        self.embeddings = GraphConvolution(input_dim=hidden1,\n",
        "                                           output_dim=hidden2,\n",
        "                                           adj=self.adj,\n",
        "                                           act=lambda x: x,\n",
        "                                           dropout=self.dropout,\n",
        "                                           logging=self.logging)(self.hidden1)\n",
        "\n",
        "        self.z_mean = self.embeddings\n",
        "\n",
        "        self.reconstructions = InnerProductDecoder(input_dim=hidden2,\n",
        "                                      act=lambda x: x,\n",
        "                                      logging=self.logging)(self.embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimizer"
      ],
      "metadata": {
        "id": "fBL84Q2LZsiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# flags = tf.app.flags\n",
        "# FLAGS = flags.FLAGS"
      ],
      "metadata": {
        "id": "BwCYnv5Dgf4x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizerAE(object):\n",
        "    def __init__(self, preds, labels, pos_weight, norm):\n",
        "        preds_sub = preds\n",
        "        labels_sub = labels\n",
        "\n",
        "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # Adam Optimizer\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.cost)\n",
        "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "                                           tf.cast(labels_sub, tf.int32))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"
      ],
      "metadata": {
        "id": "tYcpYZWBgmxf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ShIRo1amL_t3"
      },
      "outputs": [],
      "source": [
        "# class OptimizerVAE(object):\n",
        "#     def __init__(self, preds, labels, model, num_nodes, pos_weight, norm):\n",
        "#         preds_sub = preds\n",
        "#         labels_sub = labels\n",
        "\n",
        "#         self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "#         self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
        "\n",
        "#         # Latent loss\n",
        "#         self.log_lik = self.cost\n",
        "#         self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n",
        "#                                                                    tf.square(tf.exp(model.z_log_std)), 1))\n",
        "#         self.cost -= self.kl\n",
        "\n",
        "#         self.opt_op = self.optimizer.minimize(self.cost)\n",
        "#         self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
        "\n",
        "#         self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
        "#                                            tf.cast(labels_sub, tf.int32))\n",
        "#         self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "aXlIP2yNZ7hY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import"
      ],
      "metadata": {
        "id": "kMzIWXjWYPqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KO7kRq_9Lm-_"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Train on CPU (hide GPU) due to memory constraints\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qALETgJ4a12s",
        "outputId": "1f30118f-efd1-43f1-d8d2-1acc4aa77a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gae/gae\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gae/gae"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings\n",
        "hyper parameters"
      ],
      "metadata": {
        "id": "FexCj7amebmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mvMX8Zoabw3H"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "\n",
        "learning_rate= 0.01\n",
        "epochs= 200\n",
        "hidden1= 32\n",
        "hidden2= 16\n",
        "weight_decay= 0\n",
        "dropout= 0\n",
        "\n",
        "\n",
        "# model_str = model\n",
        "dataset_str = 'cora'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data \n"
      ],
      "metadata": {
        "id": "c-vkeh4iefx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6fKASODfbPaI"
      },
      "outputs": [],
      "source": [
        "# Load data \n",
        "adj, features = load_data(dataset_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a84Cbz1vhJwk"
      },
      "source": [
        "Our own data instead of above run\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yAGhnjXurh4S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKS81wsIjnZU",
        "outputId": "f22ddb1e-2704-4ff4-c684-fbe282da374e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-WgOpNUsjnim"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Content_Top1-BERT.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')\n",
        "# data = list(objecta.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3F5lER9VqH1O"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta)\n",
        "node_names = tmp.columns\n",
        "nodeslist = tmp.columns.values\n",
        "# np.sum(nodeslist == 26285)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XHVC01-TjnrQ"
      },
      "outputs": [],
      "source": [
        "tmp=pd.DataFrame.from_dict(objecta).to_numpy()\n",
        "feats = tmp.transpose()\n",
        "# print(feats.shape)\n",
        "features = sp.lil_matrix(feats)\n",
        "tmp=pd.DataFrame.from_dict(objecta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "En452TQ3mT_H"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Indexes_Top1-byTRM-Dic.data', 'rb') as f:\n",
        "  objecta = pkl.load(f, encoding='latin1')\n",
        "# objecta.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "evZeURKGkY71"
      },
      "outputs": [],
      "source": [
        "edjs=[]\n",
        "for idx, targets in objecta.items():\n",
        "  if idx in nodeslist:\n",
        "    target_str = targets.split(',')\n",
        "    for j in target_str:\n",
        "      if int(j) in nodeslist:\n",
        "        edjs.append((idx, int(j)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5mSGObhxkZHC"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph()\n",
        "G.add_edges_from(edjs)\n",
        "# A = nx.adjacency_matrix(G, nodelist=nodeslist)\n",
        "degrees = [node for (node, val) in G.degree() if val>1]\n",
        "A = nx.adjacency_matrix(G, nodelist=degrees)\n",
        "# A.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lAu4CJXNs2DK"
      },
      "outputs": [],
      "source": [
        "feats = tmp.loc[:, degrees].transpose()\n",
        "# feats.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "q_7fpGkSu64B"
      },
      "outputs": [],
      "source": [
        "features = sp.lil_matrix(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "l0SjN0nRhMre"
      },
      "outputs": [],
      "source": [
        "adj=A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store original adjacency matrix (without diagonal entries) for later\n"
      ],
      "metadata": {
        "id": "Yo3kcZHDe0A5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vOLk0K_PbqUy"
      },
      "outputs": [],
      "source": [
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "\n",
        "# if FLAGS.features == 0:\n",
        "#     features = sp.identity(features.shape[0])  # featureless"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some preprocessing"
      ],
      "metadata": {
        "id": "Abq6PpoFe46m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QugchzLycEZm"
      },
      "outputs": [],
      "source": [
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-b_l7fZodN5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f069c971-54f1-4b30-89da-c9ca92f903db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define placeholders"
      ],
      "metadata": {
        "id": "FyUHfYHue8OO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "d-hrR_zycoeh"
      },
      "outputs": [],
      "source": [
        "# Define placeholders\n",
        "placeholders = {\n",
        "    'features': tf.sparse_placeholder(tf.float32),\n",
        "    'adj': tf.sparse_placeholder(tf.float32),\n",
        "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
        "    'dropout': tf.placeholder_with_default(0., shape=())\n",
        "}\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = sparse_to_tuple(features.tocoo())\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "JRg6Fbe-e_50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eAjx-RaEcytI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510fd82a-ee06-4cc5-dff7-dafa5062960e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
        "\n",
        "\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "aFJYyhCDfDn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0g-EgrcSdVDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98f5626-7997-445f-9fb0-698cfcc63ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "targets is deprecated, use labels instead\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "opt = OptimizerAE(preds=model.reconstructions,\n",
        "                          labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
        "                                                                      validate_indices=False), [-1]),\n",
        "                          pos_weight=pos_weight,\n",
        "                          norm=norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize session"
      ],
      "metadata": {
        "id": "UytevRDJfF0U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TJ0NPP0moyQp"
      },
      "outputs": [],
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "cost_val = []\n",
        "acc_val = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gFa4oL16pEjc"
      },
      "outputs": [],
      "source": [
        "def get_roc_score(edges_pos, edges_neg, emb=None):\n",
        "    if emb is None:\n",
        "        feed_dict.update({placeholders['dropout']: 0})\n",
        "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eO7IVCBlpHK4"
      },
      "outputs": [],
      "source": [
        "cost_val = []\n",
        "acc_val = []\n",
        "val_roc_score = []\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "y3zzE68afLr6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTcXDRicpIhK",
        "outputId": "0e8f8ebf-00c4-48e7-db70-3b696036c529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 train_loss= 0.79187 train_acc= 0.00228 val_roc= 0.93655 val_ap= 0.94312 time= 0.59095\n",
            "Epoch: 0002 train_loss= 0.73215 train_acc= 0.00213 val_roc= 0.93514 val_ap= 0.94177 time= 0.48268\n",
            "Epoch: 0003 train_loss= 0.68480 train_acc= 0.00213 val_roc= 0.93676 val_ap= 0.94262 time= 0.46698\n",
            "Epoch: 0004 train_loss= 0.72856 train_acc= 0.00213 val_roc= 0.93889 val_ap= 0.94448 time= 0.45811\n",
            "Epoch: 0005 train_loss= 0.68896 train_acc= 0.00213 val_roc= 0.94157 val_ap= 0.94707 time= 0.48103\n",
            "Epoch: 0006 train_loss= 0.68413 train_acc= 0.00213 val_roc= 0.94159 val_ap= 0.94824 time= 0.46720\n",
            "Epoch: 0007 train_loss= 0.69567 train_acc= 0.00213 val_roc= 0.93748 val_ap= 0.94475 time= 0.45804\n",
            "Epoch: 0008 train_loss= 0.69542 train_acc= 0.00213 val_roc= 0.93302 val_ap= 0.94107 time= 0.46870\n",
            "Epoch: 0009 train_loss= 0.68518 train_acc= 0.00213 val_roc= 0.93080 val_ap= 0.93936 time= 0.44644\n",
            "Epoch: 0010 train_loss= 0.67708 train_acc= 0.00213 val_roc= 0.92897 val_ap= 0.93786 time= 0.46758\n",
            "Epoch: 0011 train_loss= 0.68241 train_acc= 0.00213 val_roc= 0.92835 val_ap= 0.93729 time= 0.46581\n",
            "Epoch: 0012 train_loss= 0.68506 train_acc= 0.00213 val_roc= 0.92791 val_ap= 0.93720 time= 0.48658\n",
            "Epoch: 0013 train_loss= 0.67862 train_acc= 0.00213 val_roc= 0.92731 val_ap= 0.93713 time= 0.50238\n",
            "Epoch: 0014 train_loss= 0.67305 train_acc= 0.00213 val_roc= 0.92733 val_ap= 0.93814 time= 0.46870\n",
            "Epoch: 0015 train_loss= 0.67225 train_acc= 0.00213 val_roc= 0.92698 val_ap= 0.93913 time= 0.47373\n",
            "Epoch: 0016 train_loss= 0.67274 train_acc= 0.00213 val_roc= 0.92749 val_ap= 0.94062 time= 0.45484\n",
            "Epoch: 0017 train_loss= 0.67078 train_acc= 0.00217 val_roc= 0.92782 val_ap= 0.94153 time= 0.47299\n",
            "Epoch: 0018 train_loss= 0.66614 train_acc= 0.00224 val_roc= 0.92629 val_ap= 0.94137 time= 0.50113\n",
            "Epoch: 0019 train_loss= 0.66134 train_acc= 0.00255 val_roc= 0.92469 val_ap= 0.94102 time= 0.51902\n",
            "Epoch: 0020 train_loss= 0.65877 train_acc= 0.00435 val_roc= 0.92190 val_ap= 0.93952 time= 0.46617\n",
            "Epoch: 0021 train_loss= 0.65744 train_acc= 0.01140 val_roc= 0.91862 val_ap= 0.93802 time= 0.46051\n",
            "Epoch: 0022 train_loss= 0.65405 train_acc= 0.02792 val_roc= 0.91392 val_ap= 0.93642 time= 0.44773\n",
            "Epoch: 0023 train_loss= 0.64817 train_acc= 0.05008 val_roc= 0.90840 val_ap= 0.93326 time= 0.45691\n",
            "Epoch: 0024 train_loss= 0.64277 train_acc= 0.06897 val_roc= 0.90364 val_ap= 0.93027 time= 0.46423\n",
            "Epoch: 0025 train_loss= 0.63964 train_acc= 0.08179 val_roc= 0.89920 val_ap= 0.92730 time= 0.45947\n",
            "Epoch: 0026 train_loss= 0.63702 train_acc= 0.09111 val_roc= 0.89356 val_ap= 0.92291 time= 0.47222\n",
            "Epoch: 0027 train_loss= 0.63270 train_acc= 0.10113 val_roc= 0.88836 val_ap= 0.91887 time= 0.45998\n",
            "Epoch: 0028 train_loss= 0.62809 train_acc= 0.10998 val_roc= 0.88371 val_ap= 0.91493 time= 0.45569\n",
            "Epoch: 0029 train_loss= 0.62568 train_acc= 0.11670 val_roc= 0.88011 val_ap= 0.91191 time= 0.43735\n",
            "Epoch: 0030 train_loss= 0.62360 train_acc= 0.12273 val_roc= 0.87812 val_ap= 0.90921 time= 0.44775\n",
            "Epoch: 0031 train_loss= 0.61891 train_acc= 0.13345 val_roc= 0.87863 val_ap= 0.90785 time= 0.43706\n",
            "Epoch: 0032 train_loss= 0.61365 train_acc= 0.14910 val_roc= 0.88076 val_ap= 0.90748 time= 0.45795\n",
            "Epoch: 0033 train_loss= 0.60970 train_acc= 0.16885 val_roc= 0.88309 val_ap= 0.90780 time= 0.45776\n",
            "Epoch: 0034 train_loss= 0.60512 train_acc= 0.18438 val_roc= 0.88499 val_ap= 0.90923 time= 0.45915\n",
            "Epoch: 0035 train_loss= 0.59952 train_acc= 0.19275 val_roc= 0.88672 val_ap= 0.91120 time= 0.45218\n",
            "Epoch: 0036 train_loss= 0.59482 train_acc= 0.20085 val_roc= 0.88593 val_ap= 0.91020 time= 0.44434\n",
            "Epoch: 0037 train_loss= 0.59001 train_acc= 0.21776 val_roc= 0.88062 val_ap= 0.90462 time= 0.46864\n",
            "Epoch: 0038 train_loss= 0.58314 train_acc= 0.24886 val_roc= 0.86800 val_ap= 0.89318 time= 0.44226\n",
            "Epoch: 0039 train_loss= 0.57628 train_acc= 0.28997 val_roc= 0.85184 val_ap= 0.87987 time= 0.46582\n",
            "Epoch: 0040 train_loss= 0.57142 train_acc= 0.32933 val_roc= 0.84084 val_ap= 0.87007 time= 0.49606\n",
            "Epoch: 0041 train_loss= 0.56708 train_acc= 0.35528 val_roc= 0.83880 val_ap= 0.86833 time= 0.52243\n",
            "Epoch: 0042 train_loss= 0.56235 train_acc= 0.36774 val_roc= 0.84410 val_ap= 0.87312 time= 0.45532\n",
            "Epoch: 0043 train_loss= 0.55883 train_acc= 0.37469 val_roc= 0.84622 val_ap= 0.87431 time= 0.45696\n",
            "Epoch: 0044 train_loss= 0.55742 train_acc= 0.38413 val_roc= 0.84259 val_ap= 0.87068 time= 0.46207\n",
            "Epoch: 0045 train_loss= 0.55627 train_acc= 0.39931 val_roc= 0.83131 val_ap= 0.86123 time= 0.46062\n",
            "Epoch: 0046 train_loss= 0.55482 train_acc= 0.41677 val_roc= 0.82043 val_ap= 0.85255 time= 0.47655\n",
            "Epoch: 0047 train_loss= 0.55411 train_acc= 0.42792 val_roc= 0.82114 val_ap= 0.85379 time= 0.44145\n",
            "Epoch: 0048 train_loss= 0.55282 train_acc= 0.42877 val_roc= 0.83215 val_ap= 0.86255 time= 0.47272\n",
            "Epoch: 0049 train_loss= 0.55045 train_acc= 0.42228 val_roc= 0.84287 val_ap= 0.87123 time= 0.45546\n",
            "Epoch: 0050 train_loss= 0.54821 train_acc= 0.41511 val_roc= 0.84881 val_ap= 0.87599 time= 0.48681\n",
            "Epoch: 0051 train_loss= 0.54566 train_acc= 0.41184 val_roc= 0.85043 val_ap= 0.87702 time= 0.45507\n",
            "Epoch: 0052 train_loss= 0.54275 train_acc= 0.41254 val_roc= 0.85216 val_ap= 0.87829 time= 0.47161\n",
            "Epoch: 0053 train_loss= 0.54046 train_acc= 0.41309 val_roc= 0.85547 val_ap= 0.88073 time= 0.45475\n",
            "Epoch: 0054 train_loss= 0.53853 train_acc= 0.40947 val_roc= 0.86148 val_ap= 0.88638 time= 0.44834\n",
            "Epoch: 0055 train_loss= 0.53657 train_acc= 0.40138 val_roc= 0.86679 val_ap= 0.89179 time= 0.45801\n",
            "Epoch: 0056 train_loss= 0.53506 train_acc= 0.39167 val_roc= 0.87031 val_ap= 0.89478 time= 0.44976\n",
            "Epoch: 0057 train_loss= 0.53381 train_acc= 0.38612 val_roc= 0.87075 val_ap= 0.89503 time= 0.46518\n",
            "Epoch: 0058 train_loss= 0.53224 train_acc= 0.38835 val_roc= 0.86934 val_ap= 0.89296 time= 0.43828\n",
            "Epoch: 0059 train_loss= 0.53062 train_acc= 0.39599 val_roc= 0.86737 val_ap= 0.89069 time= 0.46487\n",
            "Epoch: 0060 train_loss= 0.52912 train_acc= 0.40377 val_roc= 0.86585 val_ap= 0.88954 time= 0.44550\n",
            "Epoch: 0061 train_loss= 0.52728 train_acc= 0.40802 val_roc= 0.86592 val_ap= 0.89002 time= 0.45480\n",
            "Epoch: 0062 train_loss= 0.52529 train_acc= 0.40953 val_roc= 0.86559 val_ap= 0.88974 time= 0.49991\n",
            "Epoch: 0063 train_loss= 0.52347 train_acc= 0.41207 val_roc= 0.86307 val_ap= 0.88771 time= 0.51004\n",
            "Epoch: 0064 train_loss= 0.52153 train_acc= 0.41896 val_roc= 0.85998 val_ap= 0.88398 time= 0.48950\n",
            "Epoch: 0065 train_loss= 0.51949 train_acc= 0.42915 val_roc= 0.85734 val_ap= 0.88052 time= 0.51592\n",
            "Epoch: 0066 train_loss= 0.51772 train_acc= 0.43811 val_roc= 0.85695 val_ap= 0.87992 time= 0.46587\n",
            "Epoch: 0067 train_loss= 0.51598 train_acc= 0.44303 val_roc= 0.85794 val_ap= 0.88079 time= 0.44915\n",
            "Epoch: 0068 train_loss= 0.51424 train_acc= 0.44461 val_roc= 0.85864 val_ap= 0.88169 time= 0.46717\n",
            "Epoch: 0069 train_loss= 0.51271 train_acc= 0.44609 val_roc= 0.85771 val_ap= 0.88088 time= 0.45233\n",
            "Epoch: 0070 train_loss= 0.51121 train_acc= 0.45028 val_roc= 0.85436 val_ap= 0.87761 time= 0.45972\n",
            "Epoch: 0071 train_loss= 0.50971 train_acc= 0.45713 val_roc= 0.85216 val_ap= 0.87516 time= 0.46393\n",
            "Epoch: 0072 train_loss= 0.50838 train_acc= 0.46365 val_roc= 0.85168 val_ap= 0.87443 time= 0.48932\n",
            "Epoch: 0073 train_loss= 0.50707 train_acc= 0.46665 val_roc= 0.85283 val_ap= 0.87567 time= 0.47850\n",
            "Epoch: 0074 train_loss= 0.50581 train_acc= 0.46635 val_roc= 0.85364 val_ap= 0.87651 time= 0.44881\n",
            "Epoch: 0075 train_loss= 0.50475 train_acc= 0.46577 val_roc= 0.85283 val_ap= 0.87555 time= 0.46273\n",
            "Epoch: 0076 train_loss= 0.50377 train_acc= 0.46786 val_roc= 0.85078 val_ap= 0.87410 time= 0.46744\n",
            "Epoch: 0077 train_loss= 0.50289 train_acc= 0.47239 val_roc= 0.84927 val_ap= 0.87240 time= 0.44575\n",
            "Epoch: 0078 train_loss= 0.50221 train_acc= 0.47625 val_roc= 0.84856 val_ap= 0.87165 time= 0.46119\n",
            "Epoch: 0079 train_loss= 0.50159 train_acc= 0.47728 val_roc= 0.84962 val_ap= 0.87202 time= 0.45730\n",
            "Epoch: 0080 train_loss= 0.50101 train_acc= 0.47552 val_roc= 0.85094 val_ap= 0.87300 time= 0.44759\n",
            "Epoch: 0081 train_loss= 0.50051 train_acc= 0.47456 val_roc= 0.84990 val_ap= 0.87189 time= 0.48423\n",
            "Epoch: 0082 train_loss= 0.49993 train_acc= 0.47638 val_roc= 0.84867 val_ap= 0.87071 time= 0.48292\n",
            "Epoch: 0083 train_loss= 0.49931 train_acc= 0.47960 val_roc= 0.84798 val_ap= 0.87013 time= 0.49137\n",
            "Epoch: 0084 train_loss= 0.49864 train_acc= 0.48143 val_roc= 0.84941 val_ap= 0.87129 time= 0.46330\n",
            "Epoch: 0085 train_loss= 0.49789 train_acc= 0.48105 val_roc= 0.85041 val_ap= 0.87253 time= 0.46560\n",
            "Epoch: 0086 train_loss= 0.49715 train_acc= 0.48065 val_roc= 0.84994 val_ap= 0.87289 time= 0.44069\n",
            "Epoch: 0087 train_loss= 0.49636 train_acc= 0.48241 val_roc= 0.84888 val_ap= 0.87282 time= 0.44031\n",
            "Epoch: 0088 train_loss= 0.49560 train_acc= 0.48523 val_roc= 0.84920 val_ap= 0.87370 time= 0.43576\n",
            "Epoch: 0089 train_loss= 0.49488 train_acc= 0.48638 val_roc= 0.84978 val_ap= 0.87475 time= 0.44059\n",
            "Epoch: 0090 train_loss= 0.49417 train_acc= 0.48583 val_roc= 0.85020 val_ap= 0.87581 time= 0.47046\n",
            "Epoch: 0091 train_loss= 0.49353 train_acc= 0.48623 val_roc= 0.84976 val_ap= 0.87565 time= 0.45862\n",
            "Epoch: 0092 train_loss= 0.49291 train_acc= 0.48847 val_roc= 0.84902 val_ap= 0.87529 time= 0.45782\n",
            "Epoch: 0093 train_loss= 0.49235 train_acc= 0.49003 val_roc= 0.84962 val_ap= 0.87692 time= 0.45270\n",
            "Epoch: 0094 train_loss= 0.49180 train_acc= 0.48950 val_roc= 0.85031 val_ap= 0.87861 time= 0.45826\n",
            "Epoch: 0095 train_loss= 0.49132 train_acc= 0.48891 val_roc= 0.84944 val_ap= 0.87803 time= 0.45794\n",
            "Epoch: 0096 train_loss= 0.49084 train_acc= 0.49015 val_roc= 0.84826 val_ap= 0.87718 time= 0.46487\n",
            "Epoch: 0097 train_loss= 0.49039 train_acc= 0.49185 val_roc= 0.84847 val_ap= 0.87804 time= 0.45216\n",
            "Epoch: 0098 train_loss= 0.48993 train_acc= 0.49163 val_roc= 0.84927 val_ap= 0.87942 time= 0.44993\n",
            "Epoch: 0099 train_loss= 0.48949 train_acc= 0.49061 val_roc= 0.84867 val_ap= 0.87910 time= 0.45891\n",
            "Epoch: 0100 train_loss= 0.48903 train_acc= 0.49122 val_roc= 0.84770 val_ap= 0.87852 time= 0.44881\n",
            "Epoch: 0101 train_loss= 0.48857 train_acc= 0.49273 val_roc= 0.84789 val_ap= 0.87920 time= 0.46919\n",
            "Epoch: 0102 train_loss= 0.48812 train_acc= 0.49269 val_roc= 0.84837 val_ap= 0.87987 time= 0.44301\n",
            "Epoch: 0103 train_loss= 0.48768 train_acc= 0.49166 val_roc= 0.84793 val_ap= 0.87971 time= 0.47150\n",
            "Epoch: 0104 train_loss= 0.48723 train_acc= 0.49211 val_roc= 0.84743 val_ap= 0.87949 time= 0.44126\n",
            "Epoch: 0105 train_loss= 0.48680 train_acc= 0.49341 val_roc= 0.84740 val_ap= 0.87971 time= 0.46252\n",
            "Epoch: 0106 train_loss= 0.48636 train_acc= 0.49343 val_roc= 0.84784 val_ap= 0.88047 time= 0.45317\n",
            "Epoch: 0107 train_loss= 0.48594 train_acc= 0.49286 val_roc= 0.84731 val_ap= 0.88009 time= 0.45498\n",
            "Epoch: 0108 train_loss= 0.48553 train_acc= 0.49359 val_roc= 0.84629 val_ap= 0.87932 time= 0.46176\n",
            "Epoch: 0109 train_loss= 0.48513 train_acc= 0.49456 val_roc= 0.84636 val_ap= 0.87975 time= 0.44217\n",
            "Epoch: 0110 train_loss= 0.48473 train_acc= 0.49430 val_roc= 0.84620 val_ap= 0.87990 time= 0.47311\n",
            "Epoch: 0111 train_loss= 0.48434 train_acc= 0.49408 val_roc= 0.84560 val_ap= 0.87974 time= 0.47757\n",
            "Epoch: 0112 train_loss= 0.48395 train_acc= 0.49495 val_roc= 0.84516 val_ap= 0.87951 time= 0.51331\n",
            "Epoch: 0113 train_loss= 0.48357 train_acc= 0.49549 val_roc= 0.84578 val_ap= 0.88044 time= 0.44398\n",
            "Epoch: 0114 train_loss= 0.48318 train_acc= 0.49498 val_roc= 0.84576 val_ap= 0.88060 time= 0.46826\n",
            "Epoch: 0115 train_loss= 0.48280 train_acc= 0.49513 val_roc= 0.84474 val_ap= 0.87988 time= 0.45226\n",
            "Epoch: 0116 train_loss= 0.48242 train_acc= 0.49591 val_roc= 0.84470 val_ap= 0.87997 time= 0.46424\n",
            "Epoch: 0117 train_loss= 0.48204 train_acc= 0.49588 val_roc= 0.84472 val_ap= 0.88018 time= 0.47509\n",
            "Epoch: 0118 train_loss= 0.48166 train_acc= 0.49554 val_roc= 0.84440 val_ap= 0.88001 time= 0.46569\n",
            "Epoch: 0119 train_loss= 0.48128 train_acc= 0.49603 val_roc= 0.84398 val_ap= 0.87966 time= 0.45714\n",
            "Epoch: 0120 train_loss= 0.48091 train_acc= 0.49646 val_roc= 0.84405 val_ap= 0.87961 time= 0.44801\n",
            "Epoch: 0121 train_loss= 0.48053 train_acc= 0.49623 val_roc= 0.84370 val_ap= 0.87919 time= 0.76613\n",
            "Epoch: 0122 train_loss= 0.48015 train_acc= 0.49639 val_roc= 0.84347 val_ap= 0.87895 time= 0.43274\n",
            "Epoch: 0123 train_loss= 0.47977 train_acc= 0.49699 val_roc= 0.84361 val_ap= 0.87934 time= 0.74943\n",
            "Epoch: 0124 train_loss= 0.47939 train_acc= 0.49701 val_roc= 0.84377 val_ap= 0.87951 time= 0.74151\n",
            "Epoch: 0125 train_loss= 0.47900 train_acc= 0.49692 val_roc= 0.84289 val_ap= 0.87867 time= 0.45551\n",
            "Epoch: 0126 train_loss= 0.47860 train_acc= 0.49746 val_roc= 0.84248 val_ap= 0.87834 time= 0.45341\n",
            "Epoch: 0127 train_loss= 0.47820 train_acc= 0.49799 val_roc= 0.84241 val_ap= 0.87856 time= 0.44792\n",
            "Epoch: 0128 train_loss= 0.47779 train_acc= 0.49797 val_roc= 0.84202 val_ap= 0.87838 time= 0.45175\n",
            "Epoch: 0129 train_loss= 0.47737 train_acc= 0.49828 val_roc= 0.84139 val_ap= 0.87803 time= 0.44528\n",
            "Epoch: 0130 train_loss= 0.47695 train_acc= 0.49888 val_roc= 0.84088 val_ap= 0.87799 time= 0.47403\n",
            "Epoch: 0131 train_loss= 0.47652 train_acc= 0.49901 val_roc= 0.84077 val_ap= 0.87807 time= 0.50414\n",
            "Epoch: 0132 train_loss= 0.47608 train_acc= 0.49925 val_roc= 0.84028 val_ap= 0.87797 time= 0.49715\n",
            "Epoch: 0133 train_loss= 0.47562 train_acc= 0.49992 val_roc= 0.84014 val_ap= 0.87813 time= 0.46787\n",
            "Epoch: 0134 train_loss= 0.47516 train_acc= 0.50021 val_roc= 0.84017 val_ap= 0.87844 time= 0.46636\n",
            "Epoch: 0135 train_loss= 0.47468 train_acc= 0.50045 val_roc= 0.83892 val_ap= 0.87773 time= 0.43264\n",
            "Epoch: 0136 train_loss= 0.47419 train_acc= 0.50106 val_roc= 0.83848 val_ap= 0.87755 time= 0.44011\n",
            "Epoch: 0137 train_loss= 0.47368 train_acc= 0.50147 val_roc= 0.83823 val_ap= 0.87752 time= 0.46427\n",
            "Epoch: 0138 train_loss= 0.47316 train_acc= 0.50170 val_roc= 0.83737 val_ap= 0.87716 time= 0.47097\n",
            "Epoch: 0139 train_loss= 0.47263 train_acc= 0.50235 val_roc= 0.83682 val_ap= 0.87694 time= 0.46152\n",
            "Epoch: 0140 train_loss= 0.47208 train_acc= 0.50290 val_roc= 0.83605 val_ap= 0.87671 time= 0.43637\n",
            "Epoch: 0141 train_loss= 0.47152 train_acc= 0.50323 val_roc= 0.83571 val_ap= 0.87677 time= 0.46159\n",
            "Epoch: 0142 train_loss= 0.47095 train_acc= 0.50385 val_roc= 0.83536 val_ap= 0.87675 time= 0.45629\n",
            "Epoch: 0143 train_loss= 0.47037 train_acc= 0.50456 val_roc= 0.83483 val_ap= 0.87651 time= 0.46956\n",
            "Epoch: 0144 train_loss= 0.46979 train_acc= 0.50502 val_roc= 0.83411 val_ap= 0.87625 time= 0.45946\n",
            "Epoch: 0145 train_loss= 0.46920 train_acc= 0.50575 val_roc= 0.83330 val_ap= 0.87625 time= 0.43952\n",
            "Epoch: 0146 train_loss= 0.46862 train_acc= 0.50656 val_roc= 0.83254 val_ap= 0.87594 time= 0.50441\n",
            "Epoch: 0147 train_loss= 0.46805 train_acc= 0.50715 val_roc= 0.83143 val_ap= 0.87539 time= 0.49983\n",
            "Epoch: 0148 train_loss= 0.46749 train_acc= 0.50802 val_roc= 0.83125 val_ap= 0.87566 time= 0.49934\n",
            "Epoch: 0149 train_loss= 0.46695 train_acc= 0.50891 val_roc= 0.83069 val_ap= 0.87581 time= 0.50132\n",
            "Epoch: 0150 train_loss= 0.46643 train_acc= 0.50943 val_roc= 0.82979 val_ap= 0.87556 time= 0.46443\n",
            "Epoch: 0151 train_loss= 0.46594 train_acc= 0.51013 val_roc= 0.82907 val_ap= 0.87566 time= 0.44180\n",
            "Epoch: 0152 train_loss= 0.46547 train_acc= 0.51090 val_roc= 0.82829 val_ap= 0.87539 time= 0.49471\n",
            "Epoch: 0153 train_loss= 0.46502 train_acc= 0.51160 val_roc= 0.82750 val_ap= 0.87524 time= 0.50162\n",
            "Epoch: 0154 train_loss= 0.46459 train_acc= 0.51212 val_roc= 0.82697 val_ap= 0.87505 time= 0.49894\n",
            "Epoch: 0155 train_loss= 0.46418 train_acc= 0.51277 val_roc= 0.82639 val_ap= 0.87492 time= 0.50507\n",
            "Epoch: 0156 train_loss= 0.46378 train_acc= 0.51319 val_roc= 0.82591 val_ap= 0.87469 time= 0.50513\n",
            "Epoch: 0157 train_loss= 0.46339 train_acc= 0.51372 val_roc= 0.82537 val_ap= 0.87446 time= 0.49673\n",
            "Epoch: 0158 train_loss= 0.46299 train_acc= 0.51446 val_roc= 0.82517 val_ap= 0.87446 time= 0.49073\n",
            "Epoch: 0159 train_loss= 0.46259 train_acc= 0.51499 val_roc= 0.82491 val_ap= 0.87440 time= 0.47953\n",
            "Epoch: 0160 train_loss= 0.46217 train_acc= 0.51563 val_roc= 0.82463 val_ap= 0.87413 time= 0.45234\n",
            "Epoch: 0161 train_loss= 0.46173 train_acc= 0.51621 val_roc= 0.82480 val_ap= 0.87427 time= 0.46097\n",
            "Epoch: 0162 train_loss= 0.46128 train_acc= 0.51682 val_roc= 0.82475 val_ap= 0.87431 time= 0.45913\n",
            "Epoch: 0163 train_loss= 0.46082 train_acc= 0.51760 val_roc= 0.82480 val_ap= 0.87414 time= 0.46277\n",
            "Epoch: 0164 train_loss= 0.46034 train_acc= 0.51832 val_roc= 0.82512 val_ap= 0.87443 time= 0.44971\n",
            "Epoch: 0165 train_loss= 0.45986 train_acc= 0.51909 val_roc= 0.82581 val_ap= 0.87491 time= 0.47118\n",
            "Epoch: 0166 train_loss= 0.45937 train_acc= 0.51999 val_roc= 0.82614 val_ap= 0.87529 time= 0.44474\n",
            "Epoch: 0167 train_loss= 0.45889 train_acc= 0.52065 val_roc= 0.82660 val_ap= 0.87560 time= 0.47904\n",
            "Epoch: 0168 train_loss= 0.45842 train_acc= 0.52159 val_roc= 0.82660 val_ap= 0.87533 time= 0.45671\n",
            "Epoch: 0169 train_loss= 0.45796 train_acc= 0.52249 val_roc= 0.82718 val_ap= 0.87575 time= 0.44482\n",
            "Epoch: 0170 train_loss= 0.45752 train_acc= 0.52323 val_roc= 0.82755 val_ap= 0.87606 time= 0.45565\n",
            "Epoch: 0171 train_loss= 0.45711 train_acc= 0.52417 val_roc= 0.82792 val_ap= 0.87632 time= 0.46202\n",
            "Epoch: 0172 train_loss= 0.45672 train_acc= 0.52493 val_roc= 0.82847 val_ap= 0.87683 time= 0.45881\n",
            "Epoch: 0173 train_loss= 0.45637 train_acc= 0.52567 val_roc= 0.82907 val_ap= 0.87735 time= 0.43190\n",
            "Epoch: 0174 train_loss= 0.45605 train_acc= 0.52664 val_roc= 0.82903 val_ap= 0.87744 time= 0.47903\n",
            "Epoch: 0175 train_loss= 0.45575 train_acc= 0.52737 val_roc= 0.82905 val_ap= 0.87778 time= 0.45110\n",
            "Epoch: 0176 train_loss= 0.45548 train_acc= 0.52809 val_roc= 0.82917 val_ap= 0.87798 time= 0.52068\n",
            "Epoch: 0177 train_loss= 0.45522 train_acc= 0.52883 val_roc= 0.82930 val_ap= 0.87819 time= 0.48801\n",
            "Epoch: 0178 train_loss= 0.45498 train_acc= 0.52942 val_roc= 0.82935 val_ap= 0.87840 time= 0.47963\n",
            "Epoch: 0179 train_loss= 0.45475 train_acc= 0.53004 val_roc= 0.82919 val_ap= 0.87828 time= 0.45271\n",
            "Epoch: 0180 train_loss= 0.45453 train_acc= 0.53049 val_roc= 0.82923 val_ap= 0.87838 time= 0.46331\n",
            "Epoch: 0181 train_loss= 0.45430 train_acc= 0.53081 val_roc= 0.82926 val_ap= 0.87836 time= 0.45047\n",
            "Epoch: 0182 train_loss= 0.45408 train_acc= 0.53128 val_roc= 0.82926 val_ap= 0.87830 time= 0.46648\n",
            "Epoch: 0183 train_loss= 0.45386 train_acc= 0.53156 val_roc= 0.82933 val_ap= 0.87829 time= 0.45516\n",
            "Epoch: 0184 train_loss= 0.45363 train_acc= 0.53174 val_roc= 0.82947 val_ap= 0.87846 time= 0.46604\n",
            "Epoch: 0185 train_loss= 0.45340 train_acc= 0.53199 val_roc= 0.82965 val_ap= 0.87858 time= 0.44193\n",
            "Epoch: 0186 train_loss= 0.45316 train_acc= 0.53210 val_roc= 0.82965 val_ap= 0.87872 time= 0.45822\n",
            "Epoch: 0187 train_loss= 0.45293 train_acc= 0.53224 val_roc= 0.83011 val_ap= 0.87898 time= 0.46040\n",
            "Epoch: 0188 train_loss= 0.45270 train_acc= 0.53224 val_roc= 0.83025 val_ap= 0.87902 time= 0.43633\n",
            "Epoch: 0189 train_loss= 0.45247 train_acc= 0.53237 val_roc= 0.83023 val_ap= 0.87887 time= 0.45545\n",
            "Epoch: 0190 train_loss= 0.45224 train_acc= 0.53228 val_roc= 0.83002 val_ap= 0.87879 time= 0.43889\n",
            "Epoch: 0191 train_loss= 0.45201 train_acc= 0.53244 val_roc= 0.82977 val_ap= 0.87851 time= 0.46838\n",
            "Epoch: 0192 train_loss= 0.45179 train_acc= 0.53245 val_roc= 0.82942 val_ap= 0.87823 time= 0.52975\n",
            "Epoch: 0193 train_loss= 0.45158 train_acc= 0.53249 val_roc= 0.82953 val_ap= 0.87836 time= 0.46511\n",
            "Epoch: 0194 train_loss= 0.45138 train_acc= 0.53232 val_roc= 0.82889 val_ap= 0.87788 time= 0.45013\n",
            "Epoch: 0195 train_loss= 0.45117 train_acc= 0.53255 val_roc= 0.82912 val_ap= 0.87812 time= 0.45177\n",
            "Epoch: 0196 train_loss= 0.45098 train_acc= 0.53226 val_roc= 0.82840 val_ap= 0.87775 time= 0.47007\n",
            "Epoch: 0197 train_loss= 0.45079 train_acc= 0.53266 val_roc= 0.82854 val_ap= 0.87797 time= 0.46782\n",
            "Epoch: 0198 train_loss= 0.45061 train_acc= 0.53227 val_roc= 0.82782 val_ap= 0.87756 time= 0.46150\n",
            "Epoch: 0199 train_loss= 0.45043 train_acc= 0.53256 val_roc= 0.82792 val_ap= 0.87763 time= 0.46615\n",
            "Epoch: 0200 train_loss= 0.45025 train_acc= 0.53238 val_roc= 0.82771 val_ap= 0.87754 time= 0.46633\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.84387712647929\n",
            "Test AP score: 0.8833713231260257\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: dropout})\n",
        "    # Run single weight update\n",
        "    outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
        "\n",
        "    # Compute average loss\n",
        "    avg_cost = outs[1]\n",
        "    avg_accuracy = outs[2]\n",
        "\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
        "    val_roc_score.append(roc_curr)\n",
        "\n",
        "    print(\"Epoch:\" , '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
        "          \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
        "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
        "print('Test ROC score: ' + str(roc_score))\n",
        "print('Test AP score: ' + str(ap_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :)\n"
      ],
      "metadata": {
        "id": "hE4aW2Atfh0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IWWHDUlcWtOr"
      },
      "outputs": [],
      "source": [
        "# https://www.programcreek.com/python/\n",
        "# https://book.pythontips.com/en/latest/args_and_kwargs.html\n",
        "\n",
        "# np.sum(A[65,:].toarray()[0])\n",
        "# degrees = [node for (node, val) in G.degree() if val>5]\n",
        "\n",
        "# tmp = np.random.rand(2072, 16)\n",
        "# def sigmoid(x): \n",
        "#         return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Predict on test set of edges\n",
        "# adj_tmp = np.dot(tmp, tmp.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IDCC3SowEG5P"
      },
      "outputs": [],
      "source": [
        "# def get_roc_score_a(edges_pos, edges_neg, emb=None):\n",
        "#     if emb is None:\n",
        "#         # feed_dict.update({placeholders['dropout']: 0})\n",
        "#         emb = tmp\n",
        "\n",
        "#     def sigmoid(x):\n",
        "#         return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#     # Predict on test set of edges\n",
        "#     adj_rec = np.dot(emb, emb.T)\n",
        "#     preds = []\n",
        "#     pos = []\n",
        "#     for e in edges_pos:\n",
        "#         preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "#         pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "#     preds_neg = []\n",
        "#     neg = []\n",
        "#     for e in edges_neg:\n",
        "#         preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "#         neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "#     preds_all = np.hstack([preds, preds_neg])\n",
        "#     labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "#     roc_score = roc_auc_score(labels_all, preds_all)\n",
        "#     ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "#     return roc_score, ap_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XurHgBQKDYip"
      },
      "outputs": [],
      "source": [
        "# adj_label = adj_train + sp.eye(adj_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "#     coo = X.tocoo()\n",
        "#     indices = np.mat([coo.row, coo.col]).transpose()\n",
        "#     return tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "\n",
        "# x = convert_sparse_matrix_to_sparse_tensor(adj_label)"
      ],
      "metadata": {
        "id": "tAkmm-py5ZZ5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "klulqViA_3Wq"
      },
      "outputs": [],
      "source": [
        "# correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(adj_tmp), 0.5), tf.int32),\n",
        "#                                            tf.cast(adj_label.todense(), tf.int32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Z5byLKFHEx2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4be27e-6ebe-46ab-eb97-f8a56b0a229d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5168038091715976 0.510831796570484\n"
          ]
        }
      ],
      "source": [
        "# roc_curr, ap_curr = get_roc_score_a(val_edges, val_edges_false)\n",
        "# print(roc_curr, ap_curr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "k_pjsEiLE7tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc629c3-6549-4fbd-bcde-5a6c43baeb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5497180103550295 0.5322798391910993\n"
          ]
        }
      ],
      "source": [
        "# roc_curr, ap_curr = get_roc_score_a(test_edges, test_edges_false)\n",
        "# print(roc_curr, ap_curr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E1CcRpGCX3De",
        "3kPmH5zMYj6Q",
        "1G_VlvyFZFWv",
        "GFs3RJdIZ995",
        "YgNYjfErZiEV",
        "LxOUv5YHYJ19",
        "fBL84Q2LZsiR",
        "FexCj7amebmj",
        "Yo3kcZHDe0A5",
        "Abq6PpoFe46m",
        "FyUHfYHue8OO",
        "JRg6Fbe-e_50",
        "aFJYyhCDfDn8",
        "UytevRDJfF0U",
        "y3zzE68afLr6"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}